{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging Face ðŸ¤— Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Hugging Face ðŸ¤— model serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_function = mlrun.import_function('function.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7fc3ec3a7a50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.add_model(\n",
    "    'mymodel',\n",
    "    class_name='HuggingFaceModelServer',\n",
    "    model_path='123',  # This is not used, just for enabling the process.\n",
    "    \n",
    "    task=\"sentiment-analysis\",\n",
    "    model_class=\"AutoModelForSequenceClassification\",\n",
    "    model_name=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    tokenizer_class=\"AutoTokenizer\",\n",
    "    tokenizer_name=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the pipeline locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-09-07 08:54:42,419 [info] model mymodel was loaded\n",
      "> 2022-09-07 08:54:42,420 [info] Loaded ['mymodel']\n"
     ]
    }
   ],
   "source": [
    "server = serving_function.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [{'label': '5 stars', 'score': 0.7272651791572571}]\n"
     ]
    }
   ],
   "source": [
    "result = server.test(\n",
    "    '/v2/models/mymodel',\n",
    "    body={\"inputs\": [\"Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ðŸ¤— Transformers.\"]}\n",
    ")\n",
    "print(f\"prediction: {result['outputs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a default model from ðŸ¤—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.serving.states.TaskStep at 0x7fc2d3472f10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.add_model(\n",
    "    'default-model',\n",
    "    class_name='HuggingFaceModelServer',\n",
    "    model_path='123',  # This is not used, just for enabling the process.\n",
    "    \n",
    "    task=\"sentiment-analysis\",\n",
    "    framework='pt', # Use `pt` for pytorch and `tf` for tensorflow.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the pipeline to our k8s cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-09-07 08:54:42,487 [info] Starting remote function deploy\n",
      "2022-09-07 08:54:43  (info) Deploying function\n",
      "2022-09-07 08:54:43  (info) Building\n",
      "2022-09-07 08:54:44  (info) Staging files and preparing base images\n",
      "2022-09-07 08:54:44  (info) Building processor image\n",
      "2022-09-07 08:56:29  (info) Build complete\n",
      "> 2022-09-07 08:57:09,536 [info] successfully deployed function: {'internal_invocation_urls': ['nuclio-default-hugging-face-serving.default-tenant.svc.cluster.local:8080'], 'external_invocation_urls': ['default-hugging-face-serving-default.default-tenant.app.yh43.iguazio-cd1.com/']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://default-hugging-face-serving-default.default-tenant.app.yh43.iguazio-cd1.com/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer our sentences through our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-09-07 08:57:09,616 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-default-hugging-face-serving.default-tenant.svc.cluster.local:8080/v2/models/default-model/predict'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'f7753a17-fa84-44fa-9264-1dc65172d05c',\n",
       " 'model_name': 'default-model',\n",
       " 'outputs': [{'label': 'POSITIVE', 'score': 0.9993784427642822}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serving_function.invoke(\n",
    "    path='v2/models/default-model/predict',\n",
    "    body={\"inputs\": [\"We are delighted that we can serve ðŸ¤— Transformers with MLRun.\"]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
