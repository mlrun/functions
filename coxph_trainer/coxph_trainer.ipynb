{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config kind = \"job\"\n",
    "%nuclio config spec.image = \"mlrun/ml-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlutils import (get_sample,\n",
    "                     get_splits,\n",
    "                     gen_sklearn_model,\n",
    "                     create_class, \n",
    "                     eval_class_model,\n",
    "                     gcf_clear)\n",
    "\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import PlotArtifact, TableArtifact\n",
    "\n",
    "from cloudpickle import dumps\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _coxph_log_model(\n",
    "    context,\n",
    "    model, \n",
    "    dataset_key: str  = \"coxhazard-summary\",\n",
    "    models_dest: str = \"models\",\n",
    "    plot_cov_groups: bool = False,\n",
    "    p_value: float = 0.005,\n",
    "    plot_key: str  = \"km-cx\",\n",
    "    plots_dest: str = \"plots\",\n",
    "    file_ext=\"csv\",\n",
    "    extra_data: dict = {}\n",
    "):\n",
    "    \"\"\"log a coxph model (and submodel locations)\n",
    "    \n",
    "    :param model:        estimated coxph model\n",
    "    :param extra_data:   if this model wants to store the locations of submodels\n",
    "                         use this\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    sumtbl = model.summary\n",
    "    \n",
    "    context.log_dataset(dataset_key, df=sumtbl,\n",
    "                        index=True, format=file_ext)\n",
    "\n",
    "    model_bin = dumps(model)\n",
    "    context.log_model(\"cx-model\", body=model_bin, \n",
    "                      artifact_path=os.path.join(context.artifact_path, models_dest),\n",
    "                      # model_dir=models_dest, \n",
    "                      model_file=\"model.pkl\")\n",
    "    # this will look at regression estimate stats and select, based on p_values,\n",
    "    # only those covariates of interest and display a plot for each vs all\n",
    "    # stratification group combos (~15 charts per stratification variable => 60 charts)\n",
    "    if plot_cov_groups:\n",
    "        select_covars = summary[summary.p<=p_value].index.values\n",
    "        for group in select_covars:\n",
    "            axs = model.plot_covariate_groups(group, values=[0, 1])\n",
    "            for ix, ax in enumerate(axs):\n",
    "                f = ax.get_figure()\n",
    "                context.log_artifact(\n",
    "                    PlotArtifact(f\"cx-{group}-{ix}\", body=plt.gcf()), \n",
    "                    local_path=f\"{plots_dest}/cx-{group}-{ix}.html\")\n",
    "                gcf_clear(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _kaplan_meier_log_model(\n",
    "    context,\n",
    "    model, \n",
    "    time_column: str = \"tenure\",\n",
    "    dataset_key: str  = \"km-timelines\",\n",
    "    plot_key: str  = \"km-survival\",\n",
    "    plots_dest: str = \"plots\",\n",
    "    models_dest: str = \"models\",\n",
    "    file_ext: str = \"csv\"\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    o = []\n",
    "    for obj in model.__dict__.keys():\n",
    "        if isinstance(model.__dict__[obj], pd.DataFrame):\n",
    "            o.append(model.__dict__[obj])\n",
    "    df = pd.concat(o, axis=1)\n",
    "    df.index.name = time_column\n",
    "    context.log_dataset(dataset_key, df=df, index=True, format=file_ext)\n",
    "    # plot the model and grab figure\n",
    "    model.plot()\n",
    "    context.log_artifact(PlotArtifact(plot_key, body=plt.gcf()), \n",
    "                         local_path=f\"{plots_dest}/{plot_key}.html\")\n",
    "    # log model\n",
    "    context.log_model(\"km-model\", \n",
    "                      body=dumps(model), \n",
    "                      model_dir=f\"{models_dest}/km\", \n",
    "                      model_file=\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    context: MLClientCtx,\n",
    "    dataset: DataItem,\n",
    "    event_column: str = \"labels\",\n",
    "    time_column: str = \"tenure\",\n",
    "    encode_cols: dict = {},\n",
    "    strata_cols: list = [],\n",
    "    plot_cov_groups: bool = False,\n",
    "    p_value: float = 0.005,\n",
    "    sample: int = -1,\n",
    "    test_size: float = 0.25,\n",
    "    valid_size: float = 0.75, # (after test removed)\n",
    "    random_state: int = 1,\n",
    "    models_dest: str = \"\",\n",
    "    plots_dest: str = \"\",\n",
    "    file_ext: str = \"csv\",\n",
    ") -> None:\n",
    "    \"\"\"train models to predict the timing of events\n",
    "    \n",
    "    Although identical in structure to other training functions, this one\n",
    "    requires generating a 'Y' that represents the age/duration/tenure of\n",
    "    the obervation, designated 'tenure' here, and a binary labels columns that\n",
    "    represents the event of interest, churned/not-churned.\n",
    "    \n",
    "    In addition, there is a strata_cols parameter, representing a list of \n",
    "    stratification (aka grouping) variables.\n",
    "    \n",
    "    :param context:           the function context\n",
    "    :param dataset:           (\"data\") name of raw data file\n",
    "    :param event_column:      ground-truth (y) labels (considered as events in this model)\n",
    "    :param time_column:       age or tenure column\n",
    "    :param encode_cols:       dictionary of names and prefixes for columns that are\n",
    "                              to hot be encoded.\n",
    "    :param strata_cols:       columns used to stratify predictors\n",
    "    :param plot_cov_groups:   \n",
    "    :param p_value:           (0.005) max p value for coeffcients selected\n",
    "    :param sample:            Selects the first n rows, or select a sample\n",
    "                              starting from the first. If negative <-1, select\n",
    "                              a random sample\n",
    "    :param test_size:         (0.25) test set size\n",
    "    :param valid_size:        (0.75) Once the test set has been removed the\n",
    "                              training set gets this proportion.\n",
    "    :param random_state:      (1) sklearn rng seed\n",
    "    :param models_dest:       destination subfolder for model artifacts\n",
    "    :param plots_dest:        destination subfolder for plot artifacts\n",
    "    :param file_ext:          format for test_set_key hold out data\n",
    "    \"\"\"\n",
    "    from lifelines.plotting import plot_lifetimes\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # deprecate:\n",
    "    models_dest = models_dest or \"models\"\n",
    "    plots_dest = plots_dest or f\"plots/{context.name}\"\n",
    "    \n",
    "    # get a sample from the raw data, Y is defined as tenure\n",
    "    raw, tenure, header = get_sample(dataset, sample, time_column)\n",
    "\n",
    "    # hot-encode (drop first not an option as feature input)\n",
    "    if encode_cols:\n",
    "        raw = pd.get_dummies(raw, \n",
    "                             columns=list(encode_cols.keys()), \n",
    "                             prefix=list(encode_cols.values()), \n",
    "                             drop_first=True)\n",
    "\n",
    "    # split the sample into train validate, test and calibration sets:\n",
    "    (xtrain, ytrain), (xvalid, yvalid), (xtest, ytest) \\\n",
    "        = get_splits(raw, tenure, 3, test_size, valid_size, random_state)\n",
    "    # removed mapped version of tenure\n",
    "    for X in [xtrain, xvalid, xtest]:\n",
    "        drop_cols = X.columns.str.startswith(time_column)\n",
    "        X.drop(X.columns[drop_cols], axis=1, inplace=True)\n",
    "    for Y in [ytrain, yvalid, ytest]:\n",
    "        Y.name = time_column\n",
    "    \n",
    "    # save test data\n",
    "    context.log_dataset(\"tenured-test-set\", \n",
    "                        df=pd.concat([xtest, ytest.to_frame()], axis=1), \n",
    "                        format=file_ext, index=False)\n",
    "\n",
    "    # KAPLAN-MEIER\n",
    "    km_model = KaplanMeierFitter().fit(ytrain, xtrain.labels)\n",
    "    _kaplan_meier_log_model(context, km_model, models_dest=models_dest)\n",
    "    \n",
    "    # COXPH\n",
    "    coxdata = pd.concat([xtrain, ytrain.to_frame()], axis=1)\n",
    "    cx_model = CoxPHFitter().fit(coxdata, time_column, event_column, \n",
    "                                 strata=strata_cols)    \n",
    "    _coxph_log_model(context, cx_model, models_dest=models_dest, \n",
    "                     plot_cov_groups=plot_cov_groups, \n",
    "                     extra_data={\"km\": f\"{models_dest}/km\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf\n",
    "import os\n",
    "mlconf.dbpath = mlconf.dbpath or \"http://mlrun-api:8080\"\n",
    "mlconf.artifact_path = mlconf.artifact_path or f\"{os.environ['HOME']}/artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"cox_hazards\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"train_model\"\n",
    "fn.spec.description = \"train any classifier using scikit-learn's API\"\n",
    "fn.metadata.categories = [\"training\", \"ml\"]\n",
    "fn.metadata.labels = {\"author\": \"yjb\", \"framework\": \"survival\"}\n",
    "\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"V3IO_HOME\" in list(os.environ):\n",
    "    # mlrun on the iguazio platform\n",
    "    from mlrun import mount_v3io\n",
    "    fn.apply(mount_v3io())\n",
    "else:\n",
    "    # mlrun is setup using the instructions at \n",
    "    # https://github.com/mlrun/mlrun/blob/master/hack/local/README.md\n",
    "    from mlrun.platforms import mount_pvc\n",
    "    fn.apply(mount_pvc(\"nfsvol\", \"nfsvol\", \"/home/jovyan/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_params = {\n",
    "    \"name\" : \"tasks survive trainer\",\n",
    "    \"params\" : {\n",
    "        \"event_column\" : \"labels\", \n",
    "        \"strata_cols\" : ['InternetService', 'StreamingMovies', 'StreamingTV', 'PhoneService'],\n",
    "        \"p_value\"     : 0.005,\n",
    "        \"encode_cols\" : {\"Contract\"       : \"Contract\",\n",
    "                         \"PaymentMethod\"  : \"Payment\"},\n",
    "        \"models_dest\" : 'models/cox',\n",
    "        \"file_ext\" : \"csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://raw.githubusercontent.com/yjb-ds/testdata/master/data/encoded-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import run_local, NewTask\n",
    "\n",
    "run = run_local(\n",
    "    NewTask(**task_params),\n",
    "    handler=train_model,\n",
    "    inputs={\"dataset\"  : DATA_URL},\n",
    "    artifact_path=os.path.join(mlconf.artifact_path, \"churn\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a peek at a pickled kaplan-meier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "model = load(open(os.path.join(mlconf.artifact_path, \"churn\", \"models/cox/km/model.pkl\"), \"rb\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([1,10,30,100,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.plot(figsize=(11,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a peek at a pickeld cox hazards default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudpickle import load\n",
    "model = load(open(os.path.join(mlconf.artifact_path, \"churn\", \"models/cox/model.pkl\"), \"rb\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some potential default analyses of coxph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.baseline_survival_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* run the following for each of the lines that passes some test (p < 0.005,for example):<br>\n",
    " `model.plot_covariate_groups('Contract_1', values=[0, 1]);`<br>\n",
    " the plot needs to have the strata decoded\n",
    " \n",
    " In the train_model above, set param `plot_cov_groups=True` and produce the following set of artifacts by selecting only those covariates whose p-values\n",
    " are below some threshold `p_value`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # need to add strata labels baseline legend\n",
    "# ax = model.plot_covariate_groups('Contract_1', values=[0, 1])\n",
    "# len(ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
