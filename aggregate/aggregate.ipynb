{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Operations\n",
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the MLRun environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import new_function, code_to_function, get_run_db, mount_v3io, NewTask, mlconf, new_model_server, run_local\n",
    "mlconf.dbpath = 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nuclio config kind = \"job\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(context,\n",
    "              df_artifact, \n",
    "              keys=None, \n",
    "              metrics=None, \n",
    "              labels=None, \n",
    "              metric_aggs=['mean'], \n",
    "              label_aggs=['max'], \n",
    "              suffix=None, \n",
    "              window=3, \n",
    "              center=False, \n",
    "              inplace=False):\n",
    "    \n",
    "    context.logger.info(df_artifact)\n",
    "    input_df = pd.read_parquet(df_artifact)\n",
    "    \n",
    "    # Verify there is work to be done\n",
    "    if not (metrics or labels):\n",
    "        context.log_artifact('df', input_df)\n",
    "        return input_df\n",
    "    \n",
    "    # Select the correct indexes\n",
    "    if keys:\n",
    "        current_index = input_df.index.names\n",
    "        indexes_to_drop = [col for col in input_df.index.names if col not in keys]\n",
    "        df = input_df.reset_index(level=indexes_to_drop)\n",
    "    else:\n",
    "        df = input_df\n",
    "    \n",
    "    # For each metrics\n",
    "    if metrics:\n",
    "        metrics_df = df.loc[:, metrics].rolling(window=window,\n",
    "                                                center=center).aggregate(metric_aggs)\n",
    "        \n",
    "        # Flatten all the aggs\n",
    "        metrics_df.columns = ['_'.join(col).strip() for col in metrics_df.columns.values]\n",
    "        \n",
    "        # Add suffix\n",
    "        if suffix:\n",
    "            metrics_df.columns = [f'{metric}_{suffix}' for metric in metrics_df.columns]\n",
    "            \n",
    "        if not inplace:\n",
    "            final_df = pd.merge(input_df, metrics_df, suffixes=('', suffix), left_index=True, right_index=True)\n",
    "        else:\n",
    "            final_df = metrics_df\n",
    "\n",
    "    # For each label\n",
    "    if labels:\n",
    "        labels_df = df.loc[:, labels].rolling(window=window,\n",
    "                                              center=center).aggregate(label_aggs)\n",
    "        # Flatten all the aggs\n",
    "        labels_df.columns = ['_'.join(col).strip() for col in labels_df.columns.values]\n",
    "        \n",
    "        # Add suffix\n",
    "        if suffix:\n",
    "            labels_df.columns = [f'{label}_{suffix}' for label in labels_df.columns]\n",
    "            \n",
    "        if metrics:\n",
    "            final_df = pd.merge(final_df, labels_df, suffixes=('', suffix), left_index=True, right_index=True)   \n",
    "        else:\n",
    "            if not inplace:\n",
    "                final_df = pd.merge(input_df, labels_df, suffixes=('', suffix), left_index=True, right_index=True)      \n",
    "            else:\n",
    "                final_df = labels_df\n",
    "        \n",
    "    # Save the result dataframe\n",
    "    # TODO: Change to log_datset\n",
    "    context.log_dataset(key='aggregate', \n",
    "                        df=final_df, \n",
    "                        format='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "Do tests using data from the `Network Operations Demo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define V3IO Client\n",
    "import v3io_frames as v3f\n",
    "client = v3f.Client('framesd:8081', container='bigdata')\n",
    "\n",
    "# Define base dirs\n",
    "project_dir = os.path.join('/', 'User', 'demo-network-operations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = client.read('tsdb', 'netops_metrics', multi_index=True)\n",
    "metrics_pq = os.path.join(project_dir, 'data', 'metrics.pq')\n",
    "metrics.to_parquet(metrics_pq, engine='pyarrow', index=True)\n",
    "metrics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = '/User/v3io/bigdata/netops_metrics_parquet/20200329T133835-20200329T143835.parquet'\n",
    "metrics = pd.read_parquet('/User/v3io/bigdata/netops_metrics_parquet/20200329T133835-20200329T143835.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Test\n",
    "Define the aggregate test task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_task = NewTask(name='aggregate',\n",
    "                         project='network-operations',\n",
    "                         params={'df_artifact': metrics_path,\n",
    "                                 'metrics': ['cpu_utilization'],\n",
    "                                 'labels': ['is_error'],\n",
    "                                 'metric_aggs': ['mean', 'sum'],\n",
    "                                 'label_aggs': ['max'],\n",
    "                                 'suffix': 'daily',\n",
    "                                 'inplace': False,\n",
    "                                 'window': 5,\n",
    "                                 'center': True},\n",
    "                         handler=aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_run = run_local(aggregate_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the code to an MLRun function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = code_to_function('aggregate', \n",
    "                      kind='job',\n",
    "                      image='mlrun/mlrun:0.4.6').apply(mount_v3io(remote='bigdata', mount_path='/User/v3io/bigdata'))\n",
    "fn.export(os.path.join(project_dir, 'yaml', 'function.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.run(aggregate_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(aggregate_run.outputs['aggregate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
