{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook function handles training and logging of xgboost models **only**, exposing both the sklearn and low level api's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steps\n",
    "1. generate an xgboost model configuration by selecting one of 5 available types\n",
    "2. get a sample of data from a data source (random rows, consecutive rows, or the entire dataset)\n",
    "3. split the data into train, validation, and test sets.  \n",
    "\n",
    "> _PLEASE NOTE_:  there are many approaches to cross validation (cv) and as many ways to implement cv in scikit learn.  In this third stage, an alternative, two-way train and test split can be created.  The training set would then, for example, serve as input to a cross validation splitter.  The latter creates multiple training and validation subsets, called folds. These folds are then input, either in sequence or in parallel into the fit algorithm.\n",
    "\n",
    "4. train the model\n",
    "5. dump the model\n",
    "6. generate predictions and probabilities\n",
    "7. (calibrate probabilities if needed, wip)\n",
    "8. calculate evaluation statistics and plots\n",
    "\n",
    "All these steps have been separated here into independent functions since many can be reused for other model types. Some of the following functions will be transferred in the `mlrun.mlutils` module. Additionally, each function contains its own imports in order to isolate and identify dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'job'\n",
      "%nuclio: setting spec.image to 'mlrun/ml-models'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config kind = \"job\"\n",
    "%nuclio config spec.image = \"mlrun/ml-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  mlrun.mlutils import (get_sample,\n",
    "                            get_splits,\n",
    "                            gen_sklearn_model,\n",
    "                            create_class, \n",
    "                            eval_class_model)\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from cloudpickle import dumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate an xgb model\n",
    "\n",
    "generate a model config using the xgboost's sklearn api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xgb_model(model_type: str, xgb_params: dict):\n",
    "    \"\"\"generate an xgboost model\n",
    "    \n",
    "    Multiple model types that can be estimated using\n",
    "    the XGBoost Scikit-Learn API.\n",
    "    \n",
    "    Input can either be a predefined json model configuration or one\n",
    "    of the five xgboost model types: \"classifier\", \"regressor\", \"ranker\",\n",
    "    \"rf_classifier\", or \"rf_regressor\".\n",
    "    \n",
    "    In either case one can pass in a params dict to modify defaults values.\n",
    "    \n",
    "    Based on `mlrun.mlutils.models.gen_sklearn_model`, see the function\n",
    "    `sklearn_classifier` in this repository.\n",
    "    \n",
    "    :param model_type: one of \"classifier\", \"regressor\",\n",
    "                       \"ranker\", \"rf_classifier\", or\n",
    "                      \"rf_regressor\"\n",
    "    :param xgb_params: class init parameters\n",
    "    \"\"\"\n",
    "    from mlrun.mlutils import get_class_fit, gen_sklearn_model\n",
    "\n",
    "    # generate model and fit function\n",
    "    mtypes = {\n",
    "        \"classifier\"   : \"xgboost.XGBClassifier\",\n",
    "        \"regressor\"    : \"xgboost.XGBRegressor\",\n",
    "        \"ranker\"       : \"xgboost.XGBRanker\",\n",
    "        \"rf_classifier\": \"xgboost.XGBRFClassifier\",\n",
    "        \"rf_regressor\" : \"xgboost.XGBRFRegressor\"\n",
    "    }\n",
    "    if model_type.endswith(\"json\"):\n",
    "        model_config = model_type\n",
    "    elif model_type in mtypes.keys():\n",
    "        model_config = mtypes[model_type]\n",
    "    else:\n",
    "        raise Exception(\"unrecognized model type, see help documentation\")\n",
    "\n",
    "    return gen_sklearn_model(model_config, xgb_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    context: MLClientCtx,\n",
    "    model_type: str,\n",
    "    dataset: DataItem,\n",
    "    label_column: str = \"labels\",\n",
    "    sample: int = -1,\n",
    "    test_size: float = 0.05,\n",
    "    valid_size: float = 0.75,\n",
    "    random_state: int = 1,\n",
    "    model_filename: str = \"xgb-model\",\n",
    "    models_dest: str = \"\",\n",
    "    plots_dest: str = \"\",\n",
    "    score_method: str = \"micro\",\n",
    "    file_ext: str = \"parquet\",\n",
    "    model_pkg_file: str = \"\",    \n",
    ") -> None:\n",
    "    \"\"\"train an xgboost model.\n",
    "\n",
    "    :param context:           the function context\n",
    "    :param model_type:        the model type to train, 'classifier', 'regressor'...\n",
    "    :param dataset:           (\"data\") name of raw data file\n",
    "    :param label_column:      ground-truth (y) labels\n",
    "    :param sample:            Selects the first n rows, or select a sample\n",
    "                              starting from the first. If negative <-1, select\n",
    "                              a random sample\n",
    "    :param model_filename:    model file filename,\n",
    "                              points to a directory\n",
    "    :param test_size:         (0.05) test set size\n",
    "    :param valid_size:          (0.75) Once the test set has been removed the\n",
    "                              training set gets this proportion.\n",
    "    :param random_state:      (1) sklearn rng seed\n",
    "    :param models_dest:       models subfolder on artifact path\n",
    "    :param plots_dest:        plot subfolder on artifact path\n",
    "    :param score_method:      for multiclass classification\n",
    "    \n",
    "    :param file_ext:          format for test_set_key hold out data\n",
    "    \"\"\"\n",
    "    # deprecate:\n",
    "    models_dest = models_dest or \"models\"\n",
    "    plots_dest = plots_dest or f\"plots/{context.name}\"\n",
    "    \n",
    "    # get a sample from the raw data\n",
    "    raw, labels, header = get_sample(dataset, sample, label_column)\n",
    "    \n",
    "    # split the sample into train validate, test and calibration sets:\n",
    "    (xtrain,ytrain), (xvalid,yvalid), \\\n",
    "    (xtest,ytest), (xcal, ycal) = get_splits(\n",
    "        raw, labels, 4,\n",
    "        test_size, \n",
    "        valid_size, \n",
    "        [\"labels\"],\n",
    "        random_state)\n",
    "        \n",
    "    # get model config\n",
    "    model_config = gen_xgb_model(model_type, context.parameters.items())\n",
    "    model_short_name = model_config[\"META\"][\"class\"].split('.')[-1]\n",
    "   \n",
    "    # create model instance\n",
    "    XGBBoostClass = create_class(model_config[\"META\"][\"class\"])\n",
    "    model = XGBBoostClass(**model_config[\"CLASS\"])\n",
    "\n",
    "    # update the model config with training data and callbacks\n",
    "    model_config[\"FIT\"].update({\"X\": xtrain,\"y\": ytrain.values})\n",
    "    \n",
    "    # run the fit\n",
    "    model.fit(**model_config[\"FIT\"])\n",
    "\n",
    "    # evaluate model\n",
    "    eval_metrics = eval_class_model(xvalid, yvalid, model)\n",
    "    model_plots = eval_metrics.pop(\"plots\")\n",
    "    # just do this inside log_model?\n",
    "    for plot in model_plots:\n",
    "        context.log_artifact(plot, local_path=f'plots_dest/{plot.key}.html')\n",
    "        \n",
    "    # serialize the model\n",
    "    model_bin = dumps(model.get_booster())\n",
    "    context.log_model(model_short_name, body=model_bin, \n",
    "                      model_dir=\"models\", \n",
    "                      model_file='model.pkl',\n",
    "                      metrics=eval_metrics)\n",
    "    # cant see them from log_model so try this:\n",
    "    context.log_results(eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf\n",
    "import os\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "mlconf.artifact_path = mlconf.artifact_path or f'{os.environ[\"HOME\"]}/artifacts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-05-03 02:30:50,939 warning!, server (0.4.6) and client (0.4.7) ver dont match\n",
      "[mlrun] 2020-05-03 02:30:50,972 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fdf114886d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"xgb_trainer\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"train_model\"\n",
    "fn.spec.description = \"train any classifier using scikit-learn's API\"\n",
    "fn.metadata.categories = [\"models\", \"classifier\"]\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"V3IO_HOME\" in list(os.environ):\n",
    "    # mlrun on the iguazio platform\n",
    "    from mlrun import mount_v3io\n",
    "    fn.apply(mount_v3io())\n",
    "else:\n",
    "    # mlrun is setup using the instructions at \n",
    "    # https://github.com/mlrun/mlrun/blob/master/hack/local/README.md\n",
    "    from mlrun.platforms import mount_pvc\n",
    "    fn.apply(mount_pvc(\"nfsvol\", \"nfsvol\", \"/home/joyan/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = False\n",
    "\n",
    "task_params = {\n",
    "    \"name\" : \"tasks xgb cpu trainer\",\n",
    "    \"params\" : {\n",
    "        \"model_type\"         : \"classifier\",\n",
    "        \"num_class\"          : 5,\n",
    "        \"CLASS_tree_method\"  : \"gpu_hist\" if gpus else \"hist\",\n",
    "        \"CLASS_objective\"    : \"multi:softmax\",\n",
    "        'CLASS_n_estimators' : 100,\n",
    "        \"CLASS_max_depth\"    : 6,\n",
    "        \"CLASS_booster\"      : \"gbtree\",  \n",
    "        \"CLASS_random_state\" : 1,\n",
    "        \"CLASS_base_score\" : 0.5,\n",
    "        \"CLASS_colsample_bylevel\" : 1,\n",
    "        \"CLASS_colsample_bynode\" : 1,\n",
    "        \"CLASS_colsample_bytree\" : 1,\n",
    "        \"CLASS_scale_pos_weight\" : 1,\n",
    "        \"CLASS_min_child_weight\" : 1,\n",
    "        \"sample\"             : -1,\n",
    "        \"label_column\"       : \"labels\",\n",
    "        \"test_size\"          : 0.10,\n",
    "        \"valid_size\"         : 0.75,\n",
    "        \"score_method\"       : \"weighted\",\n",
    "        \"models_dest\"        : \"xgb_trainer/models\",\n",
    "        \"plots_dest\"         : \"xgb_trainer/plots\",\n",
    "    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import run_local, NewTask\n",
    "\n",
    "run = run_local(\n",
    "    NewTask(**task_params),\n",
    "    handler=train_model,\n",
    "    inputs={\"dataset\"  : os.path.join(mlconf.artifact_path, \"classifier-data.parquet\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = fn.run(\n",
    "#     NewTask(**task_params),\n",
    "#     inputs={\"dataset\"  : os.path.join(mlconf.artifact_path, \"breast_cancer.parquet\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "\n",
    "\n",
    "# def test_gen_xgb_model():\n",
    "#     import xgboost\n",
    "#     c, j = _gen_xgb_model(\"rf_classifier\", {})\n",
    "#     assert isinstance(c, xgboost.XGBRFClassifier)\n",
    "# test_gen_xgb_model()\n",
    "\n",
    "# breast_cancer = get_dataitem(mlconf.artifact_path+\"/breast_cancer.parquet\")\n",
    "# classifier-data = get_dataitem(mlconf.artifact_path+\"/classifier-data.csv\")\n",
    "# iris = get_dataitem(mlconf.artifact_path+\"/iris.parquet\")\n",
    "\n",
    "# def test_get_sample():\n",
    "#     from mlrun import mlconf\n",
    "#     r, l, h = _get_sample(breast_cancer, -1, \"labels\")\n",
    "#     assert r.shape[0]==l.shape[0]\n",
    "# test_get_sample()\n",
    "\n",
    "# def test_get_splits():\n",
    "#     from mlrun import mlconf\n",
    "#     r, l, h = _get_sample(classifier-data, -1, \"labels\")\n",
    "#     (xtr, ytr), (xva, yva), (xte, yte), (xcal, ycal) = _get_splits(r, l, 4)\n",
    "\n",
    "#     assert xtr.shape[0]+xva.shape[0]+xte.shape[0]+xcal.shape[0] == r.shape[0]\n",
    "# test_get_splits()\n",
    "\n",
    "# #def test_save_test_set():\n",
    "# r, l, h = _get_sample(iris, -1, \"labels\")\n",
    "# A = _get_splits(r,l,3)\n",
    "# from mlrun import get_or_create_ctx\n",
    "# _save_test_set(get_or_create_ctx(\"test\"), A[2][1], A[2][1], h, debug=True)\n",
    "# import pandas as pd\n",
    "#     # pd.read_parquet()\n",
    "#     # assert\n",
    "# #test_save_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
