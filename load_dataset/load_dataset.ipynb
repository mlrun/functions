{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2018 Iguazio\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlrun.execution import MLClientCtx\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "        context: MLClientCtx,\n",
    "        dataset: str,\n",
    "        name: str = '',\n",
    "        file_ext: str = 'parquet',\n",
    "        params: dict = {}\n",
    ") -> None:\n",
    "    \"\"\"Loads a scikit-learn toy dataset for classification or regression\n",
    "\n",
    "    The following datasets are available ('name' : desription):\n",
    "\n",
    "        'boston'          : boston house-prices dataset (regression)\n",
    "        'iris'            : iris dataset (classification)\n",
    "        'diabetes'        : diabetes dataset (regression)\n",
    "        'digits'          : digits dataset (classification)\n",
    "        'linnerud'        : linnerud dataset (multivariate regression)\n",
    "        'wine'            : wine dataset (classification)\n",
    "        'breast_cancer'   : breast cancer wisconsin dataset (classification)\n",
    "\n",
    "    The scikit-learn functions return a data bunch including the following items:\n",
    "    - data              the features matrix\n",
    "    - target            the ground truth labels\n",
    "    - DESCR             a description of the dataset\n",
    "    - feature_names     header for data\n",
    "\n",
    "    The features (and their names) are stored with the target labels in a DataFrame.\n",
    "\n",
    "    For further details see https://scikit-learn.org/stable/datasets/index.html#toy-datasets\n",
    "\n",
    "    :param context:    function execution context\n",
    "    :param dataset:    name of the dataset to load\n",
    "    :param name:       artifact name (defaults to dataset)\n",
    "    :param file_ext:   output file_ext: parquet or csv\n",
    "    :param params:     params of the sklearn load_data method\n",
    "    \"\"\"\n",
    "    # reach into module and import the appropriate load_xxx function\n",
    "    pkg_module = 'sklearn.datasets'\n",
    "    fname = f'load_{dataset}'\n",
    "\n",
    "    pkg_module = __import__(pkg_module, fromlist=[fname])\n",
    "    load_data_fn = getattr(pkg_module, fname)\n",
    "\n",
    "    data = load_data_fn(**params)\n",
    "    feature_names = data['feature_names']\n",
    "\n",
    "    # create the toy dataset\n",
    "    xy = np.concatenate([data['data'], data['target'].reshape(-1, 1)], axis=1)\n",
    "    if hasattr(feature_names, 'append'):\n",
    "        # its a list\n",
    "        feature_names.append('labels')\n",
    "    else:\n",
    "        # its an array\n",
    "        feature_names = np.append(feature_names, 'labels')\n",
    "    df = pd.DataFrame(data=xy, columns=feature_names)\n",
    "\n",
    "    # log and upload the dataset\n",
    "    context.log_dataset(name or dataset, df=df, format=file_ext, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"load_dataset\", kind=\"job\", with_doc=True,\n",
    "                      handler=load_dataset, image=\"mlrun/ml-models\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"load_dataset\"\n",
    "fn.spec.description = \"load a toy dataset from scikit-learn\"\n",
    "fn.metadata.categories = [\"datagen\", \"filesutils\"]\n",
    "fn.spec.image_pull_policy = \"Always\"\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import import_function, mount_v3io, NewTask\n",
    "\n",
    "func = import_function(\"hub://load_dataset\").apply(mount_v3io())\n",
    "# func = import_function(\"function.yaml\").apply(mlrun.mount_v3io())\n",
    "\n",
    "task_params = {\"name\"          : \"tasks load toy dataset\", \n",
    "               \"params\"        : {\"dataset\"     : \"wine\"}}\n",
    "\n",
    "run = func.run(NewTask(**task_params), artifact_path=\"/User/artifacts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
