{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Drift - Deployer\n",
    "Deploy a streaming Concept Drift detector on a labeled stream.  \n",
    "\n",
    "This function is the Deployment step for the Streaming Concept Drift Detector.  It will initialize the selected drift detectors with the base_dataset's statistics and deploy the [concept_drift_streaming serverless Nuclio function](../concept_drift_streaming/concept_drift_streaming.ipynb) with them for streaming concept-drift detection on top of a labeled stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "python -m pip install scikit-multiflow==0.4.1\n",
    "python -m pip install v3io_frames\n",
    "python -m pip install nuclio-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting spec.build.baseImage to 'mlrun/ml-models'\n"
     ]
    }
   ],
   "source": [
    "# Define function spec\n",
    "%nuclio config spec.build.baseImage = \"mlrun/ml-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: start-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skmultiflow.drift_detection # We will grab our PH, DDM, EDDM algorithms from here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from cloudpickle import dumps, load, dump\n",
    "\n",
    "from nuclio.triggers import V3IOStreamTrigger \n",
    "from mlrun import DataItem, import_function, mlconf, MLClientCtx, mount_v3io\n",
    "\n",
    "# For testing\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concept_drift_deployer(context: MLClientCtx, base_dataset:DataItem, \n",
    "                           input_stream:str, output_stream:str, output_tsdb:str, tsdb_batch_size:int, callbacks:list, \n",
    "                           models:list=['ddm', 'eddm', 'pagehinkley'], models_dest='models',\n",
    "                           pagehinkley_threshold:float=10, ddm_warning_level:float=2, ddm_out_control_level:float=3,\n",
    "                           label_col='label', prediction_col='prediction', hub_url:str=mlconf.hub_url, fn_tag:str='master'):\n",
    "    \"\"\"Deploy a streaming Concept Drift detector on a labeled stream\n",
    "       This function is the Deployment step for the Streaming Concept Drift Detector.\n",
    "       It will load the selected drift detectors and initialize them with the \n",
    "       base_dataset's statistics.  Then it will deploy the concept_drift_streaming \n",
    "       function and pass the models to it for streaming concept-drift detection on top\n",
    "       of a labeled stream. \n",
    "\n",
    "    :param context:         MLRun context\n",
    "    :param base_dataset:    Dataset containing label_col and prediction_col to initialize the detectors\n",
    "    :param input_stream:    labeled stream to track.\n",
    "                            Should contain label_col and prediction_col\n",
    "    :param output_stream:   Output stream to push the detector's alerts\n",
    "    :param output_tsdb:     Output TSDB table to allow analysis and display\n",
    "    :param tsdb_batch_size: Batch size of alerts to buffer before pushing to the TSDB\n",
    "    :param callbacks:       Additional rest endpoints to send the alert data to\n",
    "    :param models:          List of the detectors to deploy\n",
    "                            Defaults to ['ddm', 'eddm', 'pagehinkley'].\n",
    "    :param models_dest:     Location for saving the detectors\n",
    "                            Defaults to 'models' (in relation to artifact_path).\n",
    "    :param pagehinkley_threshold:  Drift level threshold for PH detector Defaults to 10.\n",
    "    :param ddm_warning_level:      Warning level alert for DDM detector Defaults to 2.\n",
    "    :param ddm_out_control_level:  Drift level alert for DDM detector Defaults to 3.\n",
    "    :param label_col:       Label column to be used on base_dataset and input_stream\n",
    "                            Defaults to 'label'.\n",
    "    :param prediction_col:  Prediction column to be used on base_dataset and input_stream\n",
    "                            Defaults to 'prediction'.\n",
    "    :param hub_url:         hub_url in case the default is not used, concept_drift_streaming will be loaded\n",
    "                            by this url\n",
    "                            Defaults to mlconf.hub_url.\n",
    "    :param fn_tag:          hub tag to use\n",
    "                            Defaults to 'master'\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the streaming function\n",
    "    mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "    mlconf.hub_url = hub_url\n",
    "    fn = import_function(url='hub://concept_drift_streaming')\n",
    "    \n",
    "    # Load test dataset\n",
    "    context.logger.info('Loading base dataset')\n",
    "    base_df = base_dataset.as_df()\n",
    "    error_stream = np.where(base_df[prediction_col].values==base_df[label_col].values, 0, 1)\n",
    "    \n",
    "    # Create models\n",
    "    context.logger.info('Creating models')\n",
    "    models = [model.strip() for model in os.getenv('models', 'pagehinkley, ddm, eddm').split(',')]\n",
    "    models = {'eddm': skmultiflow.drift_detection.EDDM(),\n",
    "              'pagehinkley': skmultiflow.drift_detection.PageHinkley(min_instances=len(error_stream),\n",
    "                                                                     threshold=pagehinkley_threshold),\n",
    "              'ddm': skmultiflow.drift_detection.DDM(min_num_instances=len(error_stream),\n",
    "                                                     warning_level=ddm_warning_level,\n",
    "                                                     out_control_level=ddm_out_control_level)}\n",
    "    \n",
    "    # Initialzie the models with the base dataset\n",
    "    context.logger.info('Streaming data to models')\n",
    "    for i in range(len(error_stream)):\n",
    "        for model_name, model in models.items():\n",
    "            model.add_element(error_stream[i])\n",
    "            \n",
    "    # Save warm models\n",
    "    context.logger.info('Logging ready models')\n",
    "    for name, model in models.items():\n",
    "        data = dumps(model)\n",
    "        model_file = f'{name}.pkl'\n",
    "        context.log_model(f'{name}_concept_drift', body=data, labels={'framework': 'skmultiflow', 'workflow': 'concept-drift'},\n",
    "                          model_file=model_file, model_dir=models_dest, tag='latest')\n",
    "        fn.set_envs({f'{name}_model_path': os.path.join(context.artifact_path, models_dest, model_file)})\n",
    "            \n",
    "    # Deploy streaming concept drift function\n",
    "    # with the warm models\n",
    "    context.logger.info('Deploying Concept Drift Streaming function')\n",
    "    fn.set_envs({'label_col': label_col,\n",
    "                 'prediction_col': prediction_col, \n",
    "                 'drift_stream': output_stream,\n",
    "                 'tsdb_table': output_tsdb,\n",
    "                 'pagehinkley_threshold': pagehinkley_threshold,\n",
    "                 'ddm_warning_level': ddm_warning_level,\n",
    "                 'ddm_out_control': ddm_out_control_level})    \n",
    "    fn.add_trigger('labeled_stream', V3IOStreamTrigger(url=input_stream, name='labeled_stream'))\n",
    "    fn.apply(mount_v3io())\n",
    "    fn.deploy(project=context.project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local test\n",
    "A usecase based run example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import run_local, NewTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = 'bigdata'\n",
    "base_table = os.path.join('/', container, 'network-operations')\n",
    "stream_consumer_group = 'cd'\n",
    "artifacts_path = os.path.join(os.getcwd(), 'artifacts')\n",
    "\n",
    "task = NewTask(name='concept_drift_deployer',\n",
    "        project='network-operations',\n",
    "        handler=concept_drift_deployer,\n",
    "        params={'models': ['ddm', 'eddm', 'pagehinkley'],\n",
    "                'label_col': 'is_error',\n",
    "                'prediction_col': 'yscore',\n",
    "                'output_tsdb': os.path.join(base_table, 'drift_tsdb'),\n",
    "                'input_stream': f'http://{os.environ[\"V3IO_API\"]}{os.path.join(base_table, 'inference_stream')}@{stream_consumer_group}',\n",
    "                'output_stream': os.path.join(base_table, 'drift_stream')},\n",
    "        inputs={'base_dataset': 'store://network-operations/test_test_set_preds'},\n",
    "        artifact_path=artifacts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_local(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save function yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from mlrun import run_local, NewTask, mlconf, import_function, mount_v3io, code_to_function\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-12-23 12:39:26,663 [info] function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb816dc7450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"concept_drift\", \n",
    "                      kind='job',\n",
    "                      with_doc=True,\n",
    "                      embed_code=True)\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"concept_drift_deployer\"\n",
    "fn.spec.description = \"Deploy a streaming Concept Drift detector on a labeled stream\"\n",
    "fn.metadata.categories = [\"ml\", \"serve\"]\n",
    "fn.metadata.labels = {\"author\": \"orz\", \"framework\": \"sklearn\"}\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f40cd475160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn.apply(mount_v3io())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.run(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
