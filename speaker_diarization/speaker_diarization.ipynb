{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81bf43d-b449-4c94-a95b-fea9738b74f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Speaker diarization\n",
    "\n",
    "A function to do speaker diarization (who speaks when) on a directory of audio files\n",
    "\n",
    "In this notebook we will go over the function's docs and outputs and see an end-to-end example of running it.\n",
    "\n",
    "1. [Documentation](#chapter1)\n",
    "2. [End-to-end Demo](#chapter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4cd70-d204-415e-93a1-49598ca9c22e",
   "metadata": {},
   "source": [
    "<a id=\"chapter1\"></a>\n",
    "## 1. Documentation\n",
    "\n",
    "The function receive a directory path with all the audio files in it. It walk through the directory, get all the audio file. Then it does the speaker diarization on these audio files to detect who speaks when. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9c215-efd7-460c-ba81-9522d9997f0f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.1. Parameters:\n",
    "* **context**: `mlrun.MLClientCtx`\n",
    "    \n",
    "    The MLRun context\n",
    "    \n",
    "* **input_path**: `str`\n",
    " \n",
    "    The input directory with all the audio files (now we support mp3, flv, mp4, wma, wav formats)\n",
    "     \n",
    "* **output_directory**: `str`\n",
    " \n",
    "    The directory that is used to store the result of the nemo diarization pipeline. \n",
    "     \n",
    "* **condition_show_plot**: `bool`\n",
    "    If set to true, the diarization results will be plotted in the notebook\n",
    "    \n",
    "* **num_speakers**: `int`\n",
    "    Number of sepakers in the audio file\n",
    "    \n",
    "* **vad_model**: `str`\n",
    "    Name of the VAD model to use\n",
    "    \n",
    "* **speaker_embeddings_model**: `str`\n",
    "    Name of the speaker embeddings model to use\n",
    "    \n",
    "* **msdd_model**: `str`\n",
    "    Name of the msdd model to use\n",
    "    \n",
    "* **msdd_model**: `str`\n",
    "    Name of the msdd model to use\n",
    "    \n",
    "* **device**: `str`\n",
    "    Device to use for diarization (default cuda if cuda available, else cpu)\n",
    "    \n",
    "* **kwargs**: `dict`\n",
    "    Additional arguments to pass to the diarizer following the format <config_name>__<parameter_name>__<attribute_name>.\n",
    "    The diarization pipeline has 5 configs: GeneralConfig, VADConfig, SpeakerEmbeddingConfig, ClusteringConfig, MSDDConfig. For different config we have different parameters to pass. Please refer to Nemo's [documentation](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/speaker_diarization/intro.html#) for details. Please note the default configurations in this function is suitable for telephone recordings involving 2~8 speakers in a session and may not show the best performance on the other types of acoustic conditions or dialogues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac8b8d-08bb-4a0f-ad16-f830efc1f8f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2. Outputs:\n",
    "\n",
    "There are two outputs of this function. Please note for each audio file, we will log a dataframe of the speaker segments.\n",
    "\n",
    "* **output_path**: `str`\n",
    "    \n",
    "    The directory stored all the Nemo results \n",
    "    \n",
    "* **errors** : `dict`\n",
    "    A dict of errors when processing the audio files if any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40a194-6589-4c3a-8852-37a281d4ee00",
   "metadata": {},
   "source": [
    "<a id=\"chapter2\"></a>\n",
    "## 2. Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb09c07-07d1-4766-9a00-b4bf19cb2fff",
   "metadata": {},
   "source": [
    "### 2.1 Importing the speaker_diarization function from hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72432f-3bca-4d86-9f73-c10c3a53766a",
   "metadata": {},
   "source": [
    "To import the function directly from hub, use:\n",
    "\n",
    "speaker_diarization = mlrun.import_function(\"hub://speaker_diarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38589ec9-f639-4a2a-aed7-413e19e0df58",
   "metadata": {},
   "source": [
    "### 2.2 Run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688496be-2fd6-42b3-87a9-5d219c99fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import mlrun\n",
    "artifact_path = tempfile.mktemp()\n",
    "speaker_diarization_func = mlrun.import_function(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ae98b2-a3b8-412f-b2a5-ec3d22ee969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-29 06:23:41,423 [info] Storing function: {'name': 'speaker-diarization-diarize', 'uid': 'cd6adcce200046be98a3826b10431717', 'db': None}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337d7b661ff1461c833c2d0a91b14ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Diarizing:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:01 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
      "[NeMo I 2023-08-29 06:24:01 cloud:58] Found existing object /User/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2023-08-29 06:24:01 cloud:64] Re-using file from: /User/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
      "[NeMo I 2023-08-29 06:24:01 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-08-29 06:24:01 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-08-29 06:24:01 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-08-29 06:24:01 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:01 features:289] PADDING: 16\n",
      "[NeMo I 2023-08-29 06:24:02 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /User/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2023-08-29 06:24:02 clustering_diarizer:157] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2023-08-29 06:24:02 cloud:58] Found existing object /User/.cache/torch/NeMo/NeMo_1.20.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
      "[NeMo I 2023-08-29 06:24:02 cloud:64] Re-using file from: /User/.cache/torch/NeMo/NeMo_1.20.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
      "[NeMo I 2023-08-29 06:24:02 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-08-29 06:24:02 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-08-29 06:24:02 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:02 features:289] PADDING: 16\n",
      "[NeMo I 2023-08-29 06:24:02 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /User/.cache/torch/NeMo/NeMo_1.20.0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-08-29 06:24:02 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:02 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2023-08-29 06:24:02 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "splitting manifest:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "splitting manifest: 100%|██████████| 1/1 [00:17<00:00, 17.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:20 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
      "[NeMo I 2023-08-29 06:24:20 classification_models:272] Perform streaming frame-level VAD\n",
      "[NeMo I 2023-08-29 06:24:20 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-08-29 06:24:20 collections:302] Dataset loaded with 3 items, total duration of  0.04 hours.\n",
      "[NeMo I 2023-08-29 06:24:20 collections:304] # 3 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "vad:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A[NeMo W 2023-08-29 06:24:20 nemo_logging:349] User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "    \n",
      "\n",
      "vad:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]\u001b[A\n",
      "vad:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
      "vad: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:23 clustering_diarizer:250] Generating predictions with overlapping input segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating preds:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "generating preds: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\u001b[A\n",
      "                                                               \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:24 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "creating speech segments:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, output/real_state/speaker_outputs/subsegments_scale0.json\n",
      "[NeMo I 2023-08-29 06:24:25 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2023-08-29 06:24:25 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-08-29 06:24:25 collections:302] Dataset loaded with 178 items, total duration of  0.07 hours.\n",
      "[NeMo I 2023-08-29 06:24:25 collections:304] # 178 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[1/5] extract embeddings:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "[1/5] extract embeddings:  33%|███▎      | 1/3 [00:02<00:04,  2.46s/it]\u001b[A\n",
      "[1/5] extract embeddings:  67%|██████▋   | 2/3 [00:04<00:02,  2.13s/it]\u001b[A\n",
      "[1/5] extract embeddings: 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:31 clustering_diarizer:389] Saved embedding files to output/real_state/speaker_outputs/embeddings\n",
      "[NeMo I 2023-08-29 06:24:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, output/real_state/speaker_outputs/subsegments_scale1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:31 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2023-08-29 06:24:31 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-08-29 06:24:31 collections:302] Dataset loaded with 215 items, total duration of  0.07 hours.\n",
      "[NeMo I 2023-08-29 06:24:31 collections:304] # 215 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] extract embeddings:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "[2/5] extract embeddings:  25%|██▌       | 1/4 [00:02<00:07,  2.40s/it]\u001b[A\n",
      "[2/5] extract embeddings:  50%|█████     | 2/4 [00:03<00:03,  1.84s/it]\u001b[A\n",
      "[2/5] extract embeddings:  75%|███████▌  | 3/4 [00:04<00:01,  1.50s/it]\u001b[A\n",
      "[2/5] extract embeddings: 100%|██████████| 4/4 [00:05<00:00,  1.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:37 clustering_diarizer:389] Saved embedding files to output/real_state/speaker_outputs/embeddings\n",
      "[NeMo I 2023-08-29 06:24:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, output/real_state/speaker_outputs/subsegments_scale2.json\n",
      "[NeMo I 2023-08-29 06:24:37 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2023-08-29 06:24:37 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-08-29 06:24:37 collections:302] Dataset loaded with 270 items, total duration of  0.07 hours.\n",
      "[NeMo I 2023-08-29 06:24:37 collections:304] # 270 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] extract embeddings:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "[3/5] extract embeddings:  20%|██        | 1/5 [00:02<00:09,  2.36s/it]\u001b[A\n",
      "[3/5] extract embeddings:  40%|████      | 2/5 [00:03<00:05,  1.68s/it]\u001b[A\n",
      "[3/5] extract embeddings:  60%|██████    | 3/5 [00:04<00:02,  1.43s/it]\u001b[A\n",
      "[3/5] extract embeddings:  80%|████████  | 4/5 [00:05<00:01,  1.26s/it]\u001b[A\n",
      "[3/5] extract embeddings: 100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:44 clustering_diarizer:389] Saved embedding files to output/real_state/speaker_outputs/embeddings\n",
      "[NeMo I 2023-08-29 06:24:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, output/real_state/speaker_outputs/subsegments_scale3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:44 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2023-08-29 06:24:44 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-08-29 06:24:44 collections:302] Dataset loaded with 363 items, total duration of  0.08 hours.\n",
      "[NeMo I 2023-08-29 06:24:44 collections:304] # 363 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] extract embeddings:   0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "[4/5] extract embeddings:  17%|█▋        | 1/6 [00:02<00:10,  2.03s/it]\u001b[A\n",
      "[4/5] extract embeddings:  33%|███▎      | 2/6 [00:03<00:06,  1.70s/it]\u001b[A\n",
      "[4/5] extract embeddings:  50%|█████     | 3/6 [00:04<00:03,  1.28s/it]\u001b[A\n",
      "[4/5] extract embeddings:  67%|██████▋   | 4/6 [00:05<00:02,  1.11s/it]\u001b[A\n",
      "[4/5] extract embeddings:  83%|████████▎ | 5/6 [00:05<00:00,  1.02it/s]\u001b[A\n",
      "[4/5] extract embeddings: 100%|██████████| 6/6 [00:06<00:00,  1.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:50 clustering_diarizer:389] Saved embedding files to output/real_state/speaker_outputs/embeddings\n",
      "[NeMo I 2023-08-29 06:24:50 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, output/real_state/speaker_outputs/subsegments_scale4.json\n",
      "[NeMo I 2023-08-29 06:24:50 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2023-08-29 06:24:50 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-08-29 06:24:50 collections:302] Dataset loaded with 547 items, total duration of  0.08 hours.\n",
      "[NeMo I 2023-08-29 06:24:50 collections:304] # 547 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[5/5] extract embeddings:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "[5/5] extract embeddings:  11%|█         | 1/9 [00:02<00:16,  2.03s/it]\u001b[A\n",
      "[5/5] extract embeddings:  22%|██▏       | 2/9 [00:03<00:11,  1.69s/it]\u001b[A\n",
      "[5/5] extract embeddings:  33%|███▎      | 3/9 [00:04<00:07,  1.21s/it]\u001b[A\n",
      "[5/5] extract embeddings:  44%|████▍     | 4/9 [00:04<00:04,  1.04it/s]\u001b[A\n",
      "[5/5] extract embeddings:  56%|█████▌    | 5/9 [00:05<00:03,  1.28it/s]\u001b[A\n",
      "[5/5] extract embeddings:  67%|██████▋   | 6/9 [00:05<00:01,  1.54it/s]\u001b[A\n",
      "[5/5] extract embeddings:  78%|███████▊  | 7/9 [00:06<00:01,  1.71it/s]\u001b[A\n",
      "[5/5] extract embeddings:  89%|████████▉ | 8/9 [00:06<00:00,  1.96it/s]\u001b[A\n",
      "[5/5] extract embeddings: 100%|██████████| 9/9 [00:07<00:00,  1.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:57 clustering_diarizer:389] Saved embedding files to output/real_state/speaker_outputs/embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2023-08-29 06:24:57 speaker_utils:464] cuda=False, using CPU for eigen decomposition. This might slow down the clustering process.\n",
      "\n",
      "clustering:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-08-29 06:24:58 clustering_diarizer:464] Outputs are saved in /User/functions/speaker_diarization/output/real_state directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2023-08-29 06:24:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-29 06:24:59,168 [info] Done:\n",
      "  audio_file diarization_results               converted_audio_file  \\\n",
      "0          .          real_state  /tmp/converted_audio_luba6cuc.wav   \n",
      "\n",
      "  speaker_segments  \n",
      "0       real_state  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>default</td>\n",
       "      <td><div title=\"cd6adcce200046be98a3826b10431717\"><a href=\"https://dashboard.default-tenant.app.llm2.iguazio-cd0.com/mlprojects/default/jobs/monitor/cd6adcce200046be98a3826b10431717/overview\" target=\"_blank\" >...10431717</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Aug 29 06:23:41</td>\n",
       "      <td>completed</td>\n",
       "      <td>speaker-diarization-diarize</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=pengw</div><div class=\"dictlist\">kind=</div><div class=\"dictlist\">owner=pengw</div><div class=\"dictlist\">host=jupyter-pengw-5f99fb678d-zkdv7</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">input_path=./data/real_state.mp3</div><div class=\"dictlist\">output_directory=./output</div><div class=\"dictlist\">num_speakers=2</div><div class=\"dictlist\">device=cpu</div><div class=\"dictlist\">condition_show_plot=True</div></td>\n",
       "      <td></td>\n",
       "      <td><div title=\"/tmp/tmpiq1q8f5t/speaker-diarization-diarize/0/real_state.csv\">real_state</div><div title=\"/tmp/tmpiq1q8f5t/speaker-diarization-diarize/0/output_directory.zip\">output_directory</div><div title=\"/tmp/tmpiq1q8f5t/speaker-diarization-diarize/0/dataset.parquet\">dataset</div><div title=\"/tmp/tmpiq1q8f5t/speaker-diarization-diarize/0/errored_files.npz\">errored_files</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result1b8d06b6-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result1b8d06b6-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result1b8d06b6\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result1b8d06b6-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> > to track results use the .show() or .logs() methods  or <a href=\"https://dashboard.default-tenant.app.llm2.iguazio-cd0.com/mlprojects/default/jobs/monitor/cd6adcce200046be98a3826b10431717/overview\" target=\"_blank\">click here</a> to open in UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-29 06:24:59,631 [info] Run execution finished: {'status': 'completed', 'name': 'speaker-diarization-diarize'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker_diarization_run = speaker_diarization_func.run(\n",
    "    handler = \"diarize\",\n",
    "    params={\n",
    "        \"input_path\": \"./data/real_state.mp3\",\n",
    "        \"output_directory\": \"./output\",\n",
    "        \"num_speakers\": 2,\n",
    "        \"device\": \"cpu\",\n",
    "        \"condition_show_plot\": True,\n",
    "    },\n",
    "    local=True,\n",
    "    returns=[\"output_directory: path\", \"dataset: dataset\", \"errored_files\"],\n",
    "    artifact_path=artifact_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1169204d-46aa-4e26-8298-17e02a519a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'real_state': 'store://artifacts/default/speaker-diarization-diarize_real_state:cd6adcce200046be98a3826b10431717',\n",
       " 'output_directory': 'store://artifacts/default/speaker-diarization-diarize_output_directory:cd6adcce200046be98a3826b10431717',\n",
       " 'dataset': 'store://artifacts/default/speaker-diarization-diarize_dataset:cd6adcce200046be98a3826b10431717',\n",
       " 'errored_files': 'store://artifacts/default/speaker-diarization-diarize_errored_files:cd6adcce200046be98a3826b10431717'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_diarization_run.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7659182-09af-4bd9-bab7-6fa63d79ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_path += f\"/{speaker_diarization_run.metadata.name}/{speaker_diarization_run.metadata.iteration}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64d1f13-d997-4a8a-999d-575970057d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mlrun.get_dataitem(artifact_path + \"dataset.parquet\").as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a524b297-ef3c-408a-b91f-9c0c058f0bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>diarization_results</th>\n",
       "      <th>converted_audio_file</th>\n",
       "      <th>speaker_segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>real_state</td>\n",
       "      <td>/tmp/converted_audio_luba6cuc.wav</td>\n",
       "      <td>real_state</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  audio_file diarization_results               converted_audio_file  \\\n",
       "0          .          real_state  /tmp/converted_audio_luba6cuc.wav   \n",
       "\n",
       "  speaker_segments  \n",
       "0       real_state  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59e71574-4afb-4a68-9960-246a32c9520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_df = mlrun.get_dataitem(artifact_path+\"real_state.csv\").as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d44c25-5292-424f-8195-a669007a9545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060</td>\n",
       "      <td>1.050</td>\n",
       "      <td>speaker_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.860</td>\n",
       "      <td>4.090</td>\n",
       "      <td>speaker_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.980</td>\n",
       "      <td>6.970</td>\n",
       "      <td>speaker_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.940</td>\n",
       "      <td>10.410</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.860</td>\n",
       "      <td>19.485</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.485</td>\n",
       "      <td>19.690</td>\n",
       "      <td>speaker_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.900</td>\n",
       "      <td>63.210</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63.500</td>\n",
       "      <td>67.130</td>\n",
       "      <td>speaker_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67.660</td>\n",
       "      <td>73.285</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>73.285</td>\n",
       "      <td>75.535</td>\n",
       "      <td>speaker_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>75.535</td>\n",
       "      <td>75.785</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>75.785</td>\n",
       "      <td>76.035</td>\n",
       "      <td>speaker_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>76.035</td>\n",
       "      <td>76.285</td>\n",
       "      <td>speaker_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>76.285</td>\n",
       "      <td>81.290</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>81.580</td>\n",
       "      <td>103.850</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>104.540</td>\n",
       "      <td>112.250</td>\n",
       "      <td>speaker_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>112.540</td>\n",
       "      <td>127.915</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>127.915</td>\n",
       "      <td>129.415</td>\n",
       "      <td>speaker_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>129.415</td>\n",
       "      <td>136.415</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>136.415</td>\n",
       "      <td>137.165</td>\n",
       "      <td>speaker_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>137.165</td>\n",
       "      <td>146.910</td>\n",
       "      <td>speaker_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      start      end    speaker\n",
       "0     0.060    1.050  speaker_2\n",
       "1     2.860    4.090  speaker_2\n",
       "2     5.980    6.970  speaker_2\n",
       "3     8.940   10.410  speaker_0\n",
       "4    10.860   19.485  speaker_0\n",
       "5    19.485   19.690  speaker_2\n",
       "6    19.900   63.210  speaker_0\n",
       "7    63.500   67.130  speaker_1\n",
       "8    67.660   73.285  speaker_0\n",
       "9    73.285   75.535  speaker_1\n",
       "10   75.535   75.785  speaker_0\n",
       "11   75.785   76.035  speaker_2\n",
       "12   76.035   76.285  speaker_1\n",
       "13   76.285   81.290  speaker_0\n",
       "14   81.580  103.850  speaker_0\n",
       "15  104.540  112.250  speaker_1\n",
       "16  112.540  127.915  speaker_0\n",
       "17  127.915  129.415  speaker_1\n",
       "18  129.415  136.415  speaker_0\n",
       "19  136.415  137.165  speaker_1\n",
       "20  137.165  146.910  speaker_0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380fbb97-32ea-4677-99cc-cd65e9085f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcribe",
   "language": "python",
   "name": "conda-env-.conda-transcribe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
