{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6612c5feeb0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassBalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import PlotArtifact, TableArtifact\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from yellowbrick import ClassBalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "\n",
    "def _gcf_clear(plt):\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close() \n",
    "\n",
    "def summarize(\n",
    "    context: MLClientCtx,\n",
    "    table: str,\n",
    "    label_column: str = 'labels',\n",
    "    class_labels: list[str] = None,\n",
    "    plot_hist: bool = True,\n",
    "    plots_dest: str = 'plots'\n",
    ") -> None:\n",
    "    \"\"\"Summarize a table\n",
    "\n",
    "    :param context:         the function context\n",
    "    :param table:           pandas dataframe (csv/parquet file path)\n",
    "    :param label_column:    ground truth column label\n",
    "    :param class_labels:    label for each class in tables and plots\n",
    "    :param plot_hist:       (True) set this to False for large tables\n",
    "    :param plots_dest:      destination folder of summary plots (relative to artifact_path)\n",
    "    \"\"\"\n",
    "    table = str(table)\n",
    "    if table.endswith('.csv'):\n",
    "        table = pd.read_csv(table)\n",
    "    else: \n",
    "        table = pd.read_parquet(table)\n",
    "    header = table.columns.values\n",
    "\n",
    "    _gcf_clear(plt)\n",
    "    try:\n",
    "        snsplt = sns.pairplot(table, hue=label_column, ax=ax)\n",
    "    except Exception as e:\n",
    "        snsplt = sns.pairplot(table, hue=label_column, diag_kws={'bw': 1.5})\n",
    "    context.log_artifact(PlotArtifact('histograms',  body=plt.gcf()), local_path=f\"{plots_dest}/hist.html\")\n",
    "\n",
    "    _gcf_clear(plt)   \n",
    "    labels = table.pop(label_column)\n",
    "    class_balance_model = ClassBalance(labels=class_labels)\n",
    "    class_balance_model.fit(labels)   \n",
    "    scale_pos_weight = class_balance_model.support_[0]/class_balance_model.support_[1]\n",
    "    context.log_result(\"scale_pos_weight\", f\"{scale_pos_weight:0.2f}\")\n",
    "    context.log_artifact(PlotArtifact(\"imbalance\", body=plt.gcf()), local_path=f\"{plots_dest}/imbalance.html\")\n",
    "    \n",
    "    _gcf_clear(plt)\n",
    "    tblcorr = table.corr()\n",
    "    ax = plt.axes()\n",
    "    sns.heatmap(tblcorr, ax=ax, annot=False, cmap=plt.cm.Reds)\n",
    "    ax.set_title(\"features correlation\")\n",
    "    context.log_artifact(PlotArtifact(\"correlation\",  body=plt.gcf()), local_path=f\"{plots_dest}/corr.html\")\n",
    "    _gcf_clear(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import run_local, code_to_function , NewTask, mlconf\n",
    "\n",
    "mlconf.dbpath = \"http://mlrun-api:8080\"\n",
    "mlconf.artifact_path = '/User/artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summarize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3844328d8c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create job function object from notebook code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m fn = code_to_function('describe', kind='job', with_doc=True,\n\u001b[0;32m----> 3\u001b[0;31m                       handler=summarize, image='mlrun/ml-models')\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# add metadata (for templates and reuse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summarize' is not defined"
     ]
    }
   ],
   "source": [
    "# create job function object from notebook code\n",
    "fn = code_to_function('describe', kind='job', with_doc=True,\n",
    "                      handler=summarize, image='mlrun/ml-models')\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = 'summarize'\n",
    "fn.spec.description = \"describe and visualizes dataset stats\"\n",
    "fn.metadata.categories = ['models', 'visualization']\n",
    "fn.metadata.labels = {'author': 'yjb'}\n",
    "\n",
    "fn.save()\n",
    "fn.export('function.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = os.path.join(mlconf.artifact_path, \"iris.parquet\")\n",
    "task = NewTask(handler=summarize, inputs={'table': table_path})\n",
    "run = run_local(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(table_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlrun, os\n",
    "\n",
    "# rfn = mlrun.import_function('hub://describe').apply(mlrun.mount_v3io())\n",
    "\n",
    "# tsk = rfn.run(mlrun.NewTask(params={\"table\": \"/User/tmp/classifier-data.csv\"}),\n",
    "#               artifact_path='/User/tmp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-v0.4.6",
   "language": "python",
   "name": "mlrun-v0.4.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
