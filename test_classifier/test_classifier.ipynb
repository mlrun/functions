{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from cloudpickle import load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import TableArtifact, PlotArtifact\n",
    "\n",
    "from mlutils.models import get_model_configs\n",
    "from mlutils.plots import plot_roc, plot_importance, gcf_clear\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "def _gcf_clear(plt):\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()        \n",
    "\n",
    "def test_classifier(\n",
    "    context: MLClientCtx,\n",
    "    models_dir: str, \n",
    "    test_set: str,\n",
    "    label_column: str,\n",
    "    score_method: str = 'micro',\n",
    "    key: str = \"\",\n",
    "    plots_dest: str = \"plots\"\n",
    ") -> None:\n",
    "    \"\"\"Test one or more classifier models against held-out dataset\n",
    "    \n",
    "    Using held-out test features, evaluates the peformance of the estimated model\n",
    "    \n",
    "    Can be part of a kubeflow pipeline as a test step that is run post EDA and \n",
    "    training/validation cycles\n",
    "    \n",
    "    :param context:         the function context\n",
    "    :param models_dir:      artifact models representing a folder or a folder\n",
    "    :param test_set:        test features and labels\n",
    "    :param label_column:    column name for ground truth labels\n",
    "    :param score_method:    for multiclass classification\n",
    "    :param key:             key for results artifact (maybe just a dir of artifacts for test like plots_dest)\n",
    "    :param plots_dest:       dir for test plots\n",
    "    \"\"\"\n",
    "    xtest = pd.read_parquet(str(test_set))\n",
    "    ytest = xtest.pop(label_column)\n",
    "    \n",
    "    context.header = list(xtest.columns.values)\n",
    "    \n",
    "    def _eval_model(model):\n",
    "        # enclose all except model\n",
    "        ytestb = label_binarize(ytest, classes=ytest.unique())\n",
    "        clf = load(open(os.path.join(str(models_dir), \"model\")+\".pkl\", \"rb\"))\n",
    "        if callable(getattr(clf, \"predict_proba\")):\n",
    "            y_score = clf.predict_proba(xtest.values)\n",
    "            ypred = clf.predict(xtest.values)\n",
    "            context.logger.info(f\"y_score.shape {y_score.shape}\")\n",
    "            context.logger.info(f\"ytestb.shape {ytestb.shape}\")\n",
    "            plot_roc(context, ytestb, y_score, key=f\"roc\", plots_dir=plots_dest)\n",
    "        else:\n",
    "            ypred = clf.predict(xtest.values) # refactor\n",
    "            y_score = None\n",
    "            \n",
    "        gcf_clear(plt)\n",
    "        # use sklearn >= v0.22 built in:\n",
    "       \n",
    "        metrics.plot_confusion_matrix(clf, xtest, ytest, \n",
    "                                      labels=ytest.unique(), normalize='true') \n",
    "        \n",
    "        context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf()), \n",
    "                             local_path=f\"{plots_dest}/confusion.html\")        \n",
    "    \n",
    "        if hasattr(clf, \"feature_importances_\"):\n",
    "            plot_importance(context, clf, key=f\"featimp\")\n",
    "\n",
    "        ytestb = label_binarize(ytest, classes=ytest.unique()) # if binary 0/1 labels, will return labels as is\n",
    "        context.logger.info(f\"y_score.shape {y_score.shape}\")\n",
    "        context.logger.info(f\"yvalidb.shape {ytestb.shape}\")\n",
    "        if ytestb.shape[1] > 1:\n",
    "            # label encoding was applied:\n",
    "            average_precision = metrics.average_precision_score(ytestb,\n",
    "                                                                y_score,\n",
    "                                                                average=score_method)\n",
    "            context.log_result(f\"rocauc\", metrics.roc_auc_score(ytestb, y_score))\n",
    "        else:\n",
    "            average_precision = metrics.average_precision_score(ytestb,\n",
    "                                                                y_score[:, 1],\n",
    "                                                                average=score_method)\n",
    "            context.log_result(f\"rocauc\", metrics.roc_auc_score(ytestb, y_score[:, 1]))\n",
    "\n",
    "        context.log_result(f\"avg_precscore\", average_precision)\n",
    "        context.log_result(f\"accuracy\", float(clf.score(xtest, ytest)))\n",
    "        context.log_result(f\"f1_score\", metrics.f1_score(ytest, ypred,\n",
    "                                                         average=score_method))\n",
    "\n",
    "    for model in os.listdir(str(models_dir)):\n",
    "        if model.endswith('.pkl'):\n",
    "            _eval_model(model)\n",
    "            # HACK: there is only one model here\n",
    "            best_model = model\n",
    "\n",
    "    # log 'best model' as artifact\n",
    "    context.log_artifact('TODAYS-MODELS-TEST-REPORT', local_path=best_model)\n",
    "    context.log_artifact('DEPLOY', body=b'true', local_path='DEPLOY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-26 15:24:02,259 saving function: test-classifier, tag: latest\n",
      "[mlrun] 2020-03-26 15:24:02,292 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f8020821d50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"test_classifier\", kind=\"job\", with_doc=True,\n",
    "                      handler=test_classifier, image=\"mlrun/ml-models\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"test_classifier\"\n",
    "fn.spec.description = \"test a classifier using held-out or new data\"\n",
    "fn.metadata.categories = [\"models\", \"testing\"]\n",
    "fn.spec.image_pull_policy = \"Always\"\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-26 15:24:02,320 starting run tasks - test classifier uid=7da253fb2b2342bb8a645ffe963b46b3  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-03-26 15:24:02,419 Job is running in the background, pod: tasks---test-classifier-2bqbq\n",
      "No handles with labels found to put in legend.\n",
      "[mlrun] 2020-03-26 15:24:12,893 y_score.shape (57, 2)\n",
      "[mlrun] 2020-03-26 15:24:12,894 ytestb.shape (57, 1)\n",
      "[mlrun] 2020-03-26 15:24:13,012 log artifact roc at /User/artifacts/plots/roc.html, size: 31054, db: Y\n",
      "[mlrun] 2020-03-26 15:24:13,127 log artifact confusion at /User/artifacts/plots/confusion.html, size: 20680, db: Y\n",
      "[mlrun] 2020-03-26 15:24:13,129 y_score.shape (57, 2)\n",
      "[mlrun] 2020-03-26 15:24:13,129 yvalidb.shape (57, 1)\n",
      "[mlrun] 2020-03-26 15:24:13,144 log artifact TODAYS-MODELS-TEST-REPORT at /User/artifacts/model.pkl, size: None, db: Y\n",
      "[mlrun] 2020-03-26 15:24:13,160 log artifact DEPLOY at /User/artifacts/DEPLOY, size: 4, db: Y\n",
      "\n",
      "[mlrun] 2020-03-26 15:24:13,177 run executed, status=completed\n",
      "final state: succeeded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"7da253fb2b2342bb8a645ffe963b46b3\">...3b46b3</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Mar 26 15:24:12</td>\n",
       "      <td>completed</td>\n",
       "      <td>tasks - test classifier</td>\n",
       "      <td><div class=\"dictlist\">host=tasks---test-classifier-2bqbq</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">label_column=labels</div><div class=\"dictlist\">models_dir=/User/artifacts/models</div><div class=\"dictlist\">test_set=/User/artifacts/test_set.parquet</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.9298245614035088</div><div class=\"dictlist\">avg_precscore=0.9920335330006206</div><div class=\"dictlist\">f1_score=0.9298245614035088</div><div class=\"dictlist\">rocauc=0.9900744416873448</div></td>\n",
       "      <td><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result04b282ae\" title=\"/files/artifacts/plots/roc.html\">roc</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result04b282ae\" title=\"/files/artifacts/plots/confusion.html\">confusion</div><div title=\"/User/artifacts/model.pkl\">TODAYS-MODELS-TEST-REPORT</div><div title=\"/User/artifacts/DEPLOY\">DEPLOY</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result04b282ae-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result04b282ae-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result04b282ae\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result04b282ae-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 7da253fb2b2342bb8a645ffe963b46b3  , !mlrun logs 7da253fb2b2342bb8a645ffe963b46b3 \n",
      "[mlrun] 2020-03-26 15:24:21,607 run executed, status=completed\n"
     ]
    }
   ],
   "source": [
    "from mlrun import import_function, mount_v3io\n",
    "\n",
    "func = import_function(\"hub://test_classifier\").apply(mount_v3io())\n",
    "# func = import_function(\"function.yaml\").apply(mlrun.mount_v3io())\n",
    "\n",
    "task_params = {\n",
    "    \"name\" : \"tasks - test classifier\",\n",
    "    \"params\": {\n",
    "        # Ina pipeline setting, the models_dir parameter would be the output of a training step\n",
    "        \"models_dir\"    : \"/User/artifacts/models\",\n",
    "        \"test_set\"      : \"/User/artifacts/test_set.parquet\",\n",
    "        \"label_column\"  : \"labels\"}}\n",
    "\n",
    "from mlrun import NewTask\n",
    "run = func.run(NewTask(**task_params), artifact_path=\"/User/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-v0.4.6",
   "language": "python",
   "name": "mlrun-v0.4.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
