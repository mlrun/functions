{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start here\n",
    "\n",
    "The following setup instructions are for developers, and for regular users it is assumed that alot of this will be done by an as of **yet unwritten makefile script** that is part of the install process\n",
    "\n",
    "1. **[set up](#setup)** a minimal conda environment for reproducibility\n",
    "2. do the **[suggested steps through functions](#suggetsed)** below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### long way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to install the environment named **stable**, run the following commands in a terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    conda config --add channels conda-forge\n",
    "    conda config --add channels anaconda\n",
    "    conda create -n stable numpy pandas scipy scikit-learn matplotlib seaborn pytest kfp pyarrow\n",
    "    conda install -n stable ipykernel\n",
    "    conda install -n stable -c DistrictDataLabs yellowbrick # to deprecate\n",
    "    conda activate stable\n",
    "    python -m ipykernel install --user --name=stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refresh browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dont't forget to always select the correct environment for your notebooks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short way\n",
    "\n",
    "**this approach worked on last platform, not this one for some reason**<br>\n",
    "\n",
    "the file included here **[functions-mlrun-v046-conda-pyenv-min-nodask](functions-mlrun-v046-conda-pyenv-min-nodask.txt)** contains a minimal conda environment for running the functions repo.  To clone this into a new environment locally run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    !conda create --name <YOUR_NEW_ENV_NAME> -f functions-mlrun-v046-conda-pyenv-min-nodask.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a **partial `conda list`** of the included packages:\n",
    "\n",
    "    # packages in environment at /User/.conda/envs/stable: \n",
    "\n",
    "    # Name                    Version                   Build  Channel \n",
    "    arrow-cpp                 0.15.1           py37h7cd5009_5    anaconda \n",
    "    blas                      1.0                         mkl    anaconda \n",
    "    intel-openmp              2020.0                      166    anaconda \n",
    "    ipython                   7.13.0                   pypi_0    pypi \n",
    "    joblib                    0.14.1                     py_0    anaconda \n",
    "    lightgbm                  2.3.0            py37he6710b0_0    anaconda \n",
    "    matplotlib                3.1.3                    py37_0    anaconda \n",
    "    mkl                       2019.5                      281    anaconda \n",
    "    numpy                     1.18.1           py37h4f9e942_0    anaconda \n",
    "    pandas                    1.0.2            py37h0573a6f_0    anaconda \n",
    "    pip                       20.0.2                   py37_1    anaconda \n",
    "    pyarrow                   0.15.1           py37h0573a6f_0    anaconda \n",
    "    pytest                    5.4.1                    py37_0    anaconda \n",
    "    python                    3.7.6                h0371630_2    anaconda \n",
    "    pyzmq                     19.0.0                   pypi_0    pypi \n",
    "    scikit-learn              0.22.1           py37hd81dba3_0    anaconda \n",
    "    scipy                     1.4.1            py37h0b6359f_0    anaconda \n",
    "    seaborn                   0.10.0                     py_0    anaconda \n",
    "    sqlite                    3.31.1               h7b6447c_0    anaconda \n",
    "    xgboost                   1.0.2            py37h3340039_0    conda-forge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL THE KERNEL AND GIVE IT A NAME (LIKE STABLE)\n",
    "# RESTART AND START RUNNING THE TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install specific mlrun and functions versions in the new environment\n",
    "\n",
    "(assume 0.4.6 is the stable version)\n",
    "\n",
    "    conda activate stable\n",
    "    python -m pip install git+https://github.com/mlrun/mlrun.git@development\n",
    "    git clone https://github.com/functions/functions.git@mlrun-v0.4.6\n",
    "    # run a makefile that hasn't been written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## suggested steps through functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[arc_to_parquet]()**<br>\n",
    "download remote archive files and save to parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[gen_class_data]()**<br>\n",
    "generate simulated classification data according to detailed specs.  Great for testing algorithms and metrics and whole pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[load_datasets]()**<br>\n",
    "download toy datasets from sklearn, tensorflow datasets, and other data external curated datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[open_archive]()**<br>\n",
    "download a zip or tar archive and extract its contents into a folder (preserving the directory structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[parquet_to_dask]()**<br>\n",
    "define a dask cluster, load your parquet data into it<br>\n",
    "access the dask client and dask dashboard throughout your mlrun pipeline<br>\n",
    "combine it with other mlrun dask components to build distributed machine and deep learning pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[feature engineering]()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[sklearn models]()**\n",
    "there are literally undreds of functions available that conform to the **[Scikit Learn]()** API. \n",
    "this component enables training of any sklearn class has that has a fit function, so this includes estimators, tranformers, etc...\n",
    "sklearn classes are input as strings\n",
    "classes not in the sklearn package muct have an accompanying json file that is easy to create\n",
    "xgboost and lightgbm default model configs are included in the samples-configs folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[xgboost/lightgbm]()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[neural networks]()**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[tuning]()**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
