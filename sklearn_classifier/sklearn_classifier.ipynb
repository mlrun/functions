{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from cloudpickle import dump, load\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from typing import List\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import PlotArtifact\n",
    "\n",
    "from mlutils.models import get_model_configs, create_class\n",
    "from mlutils.plots import plot_roc, plot_importance, gcf_clear\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "def train_model(\n",
    "    context: MLClientCtx,\n",
    "    model_pkg_class: str = \"\",\n",
    "    data_key: str = \"data\",\n",
    "    sample: int = -1,\n",
    "    label_column: str = \"labels\",\n",
    "    model_key: str = \"model\",\n",
    "    test_size: float = 0.05,\n",
    "    train_val_split: float = 0.75,\n",
    "    test_set_key: str = \"test_set\",\n",
    "    rng: int = 1,\n",
    "    models_dest: str = \"models\",\n",
    "    plots_dest: str = \"plots\",\n",
    "    score_method: str = \"micro\",\n",
    "    model_pkg_file: str = \"\",\n",
    "    file_ext: str = \"parquet\"\n",
    ") -> None:\n",
    "    \"\"\"train a classifier.\n",
    "\n",
    "    :param context:           the function context\n",
    "    :param model_pkg_class:   the model to train, e.g, \"sklearn.neural_networks.MLPClassifier\", \n",
    "                              or json model config\n",
    "    :param data_key:          (\"data\") name of raw data file\n",
    "    :param sample:            Selects the first n rows, or select a sample\n",
    "                              starting from the first. If negative <-1, select\n",
    "                              a random sample\n",
    "    :param label_column:      ground-truth (y) labels\n",
    "    :param model_key:         (\"model\") name of model in artifact store,\n",
    "                              points to a directory\n",
    "    :param test_size:         (0.05) test set size\n",
    "    :param train_val_split:   (0.75) Once the test set has been removed the\n",
    "                              training set gets this proportion.\n",
    "    :param test_set_key:      store the test data set under this key in the\n",
    "                              artifact store\n",
    "    :param rng:               (1) sklearn rng seed\n",
    "    :param models_dest:       models subfolder on artifact path\n",
    "    :param plots_dest:        plot subfolder on artifact path\n",
    "    :param score_method:      for multiclass classification\n",
    "    :param model_pkg_file:    json model config file\n",
    "    :param file_ext:          format for test_set_key hold out data\n",
    "    \"\"\"\n",
    "    # extract file name from DataItem\n",
    "    srcfilepath = str(data_key)\n",
    "    \n",
    "    # TODO: this should be part of data\"s metadata dealt with in another step get a data set, sample, etc...\n",
    "    # get all data or a sample\n",
    "    if (sample == -1) or (sample >= 1):\n",
    "        # get all rows, or contiguous sample starting at row 1.\n",
    "        if srcfilepath.endswith(\".csv\"):\n",
    "            raw = pd.read_csv(srcfilepath).dropna()\n",
    "        if srcfilepath.endswith(\"parquet\") or srcfilepath.endswith(\"pq\"):\n",
    "            raw = pd.read_parquet(srcfilepath).dropna()\n",
    "        else:\n",
    "            raise Exception(\"file type unhandled\")\n",
    "        labels = raw.pop(label_column)\n",
    "        raw = raw.iloc[:sample, :]\n",
    "        labels = labels.iloc[:sample]\n",
    "    else:\n",
    "        # grab a random sample\n",
    "        raw = pq.read_table(srcfilepath).to_pandas().dropna().sample(sample * -1)\n",
    "        labels = raw.pop(label_column)\n",
    "\n",
    "    # TODO: this should be part of data\"s metadata dealt with in another step\n",
    "    context.header = raw.columns.values\n",
    "    \n",
    "    # TODO: all of this should be part of a spitter component that does cv too, dealt with in another step\n",
    "    # make a hot encode copy of labels before the split\n",
    "    yb = label_binarize(labels, classes=labels.unique()) # if binary 0/1 labels, will return labels as is\n",
    "    \n",
    "    # double split to generate 3 data sets: train, validation and test\n",
    "    # with xtest,ytest set aside\n",
    "    # here we hide the binary encoded labels inside the X matrix so that when splitting we preserve order in both the encoded\n",
    "    # and non-encoded labels:\n",
    "    x, xtest, y, ytest = train_test_split(np.concatenate([raw, yb], axis=1), labels, test_size=test_size, random_state=rng)\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(x, y, train_size=train_val_split, random_state=rng)\n",
    "    # now extract the hot_encoded labels\n",
    "    ytrainb = xtrain[:, -yb.shape[1]:].copy()\n",
    "    xtrain = xtrain[:, :-yb.shape[1]].copy()\n",
    "    # extract the hot_encoded labels\n",
    "    yvalidb = xvalid[:, -yb.shape[1]:].copy()\n",
    "    xvalid = xvalid[:, :-yb.shape[1]].copy()\n",
    "    # extract the hot_encoded labels\n",
    "    ytestb = xtest[:, -yb.shape[1]:].copy()\n",
    "    xtest = xtest[:, :-yb.shape[1]].copy()                                      \n",
    "    \n",
    "    # set-aside test_set\n",
    "    test_set = pd.concat(\n",
    "        [pd.DataFrame(data=xtest, columns=context.header),\n",
    "         pd.DataFrame(data=ytest.values, columns=[label_column])],\n",
    "        axis=1,)\n",
    "    context.log_dataset(test_set_key, df=test_set, format=file_ext, index=False)\n",
    "\n",
    "    if model_pkg_file:\n",
    "        model_config = json.loads(model_pkg_file.get())\n",
    "    elif model_pkg_class:\n",
    "        model_config = get_model_configs(model_pkg_class)\n",
    "    else:\n",
    "        raise ValueError('model_pkg_file or model_pkg_class must be provided')\n",
    "    \n",
    "    for k, v in context.parameters.items():\n",
    "        if k.startswith('CLASS_'):\n",
    "            model_config['CLASS'][k[6:]] = v\n",
    "        if k.startswith('FIT_'):\n",
    "            model_config['FIT'][k[4:]] = v\n",
    "\n",
    "    model_config[\"FIT\"].update({\"X\": xtrain,\"y\": ytrain.values})\n",
    "    \n",
    "    # create class and fit\n",
    "    ClassifierClass = create_class(model_config[\"META\"][\"class\"])\n",
    "    model = ClassifierClass(**model_config[\"CLASS\"])\n",
    "    model.fit(**model_config[\"FIT\"])\n",
    "\n",
    "    # save model\n",
    "    filepath = os.path.join(context.artifact_path, f\"{models_dest}/{model_key}.pkl\")\n",
    "    os.makedirs(os.path.join(context.artifact_path, models_dest), exist_ok=True)\n",
    "    try:\n",
    "        dump(model, open(filepath, \"wb\"))\n",
    "        context.log_artifact(model_key, local_path=models_dest)\n",
    "    except Exception as e:\n",
    "        print(\"SERIALIZE MODEL ERROR:\", str(e))\n",
    "\n",
    "    # compute validation metrics\n",
    "    ypred = model.predict(xvalid)\n",
    "    y_score = model.predict_proba(xvalid)\n",
    "    context.logger.info(f\"y_score.shape {y_score.shape}\")\n",
    "    context.logger.info(f\"yvalidb.shape {yvalidb.shape}\")\n",
    "    if yvalidb.shape[1] > 1:\n",
    "        # label encoding was applied:\n",
    "        average_precision = metrics.average_precision_score(yvalidb,\n",
    "                                                            y_score,\n",
    "                                                            average=score_method)\n",
    "        context.log_result(f\"rocauc\", metrics.roc_auc_score(yvalidb, y_score))\n",
    "    else:\n",
    "        average_precision = metrics.average_precision_score(yvalidb,\n",
    "                                                            y_score[:, 1],\n",
    "                                                            average=score_method)\n",
    "        context.log_result(f\"rocauc\", metrics.roc_auc_score(yvalidb, y_score[:, 1]))\n",
    "        \n",
    "    context.log_result(f\"avg_precscore\", average_precision)\n",
    "    context.log_result(f\"accuracy\", float(model.score(xvalid, yvalid)))\n",
    "    context.log_result(f\"f1_score\", metrics.f1_score(yvalid, ypred,\n",
    "                                             average=score_method))\n",
    "\n",
    "    # TODO: missing validation plots, callbacks need to reintroduced\n",
    "    \n",
    "    plot_roc(context, yvalidb, y_score)\n",
    "    gcf_clear(plt)\n",
    "    # use sklearn >= v0.22 built in:\n",
    "    metrics.plot_confusion_matrix(model, xvalid, yvalid, labels=labels.unique(), normalize='true') \n",
    "    context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf()), local_path=f\"{plots_dest}/confusion.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-26 13:53:56,999 saving function: sklearn-classifier, tag: latest\n",
      "[mlrun] 2020-03-26 13:53:57,040 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb35ce0d610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"sklearn_classifier\", kind=\"job\", with_doc=True,\n",
    "                      handler=train_model, image=\"mlrun/ml-models:0.4.6\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"train_model\"\n",
    "fn.spec.description = \"train any classifier using scikit-learn's API\"\n",
    "fn.metadata.categories = [\"models\", \"classifier\"]\n",
    "fn.spec.image_pull_policy = \"Always\"\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import import_function, mount_v3io\n",
    "\n",
    "func = import_function(\"hub://sklearn_classifier\").apply(mount_v3io())\n",
    "# func = import_function(\"function.yaml\").apply(mlrun.mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-26 13:53:57,077 starting run tasks train a classifier uid=4225151136be49e781828ff057861a59  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-03-26 13:53:57,197 Job is running in the background, pod: tasks-train-a-classifier-2hwgv\n",
      "No handles with labels found to put in legend.\n",
      "[mlrun] 2020-03-26 13:54:07,677 log artifact test_set at /User/artifacts/test_set.parquet, size: 35553, db: Y\n",
      "[mlrun] 2020-03-26 13:54:08,304 log artifact model at /User/artifacts/models, size: None, db: Y\n",
      "[mlrun] 2020-03-26 13:54:08,305 y_score.shape (128, 2)\n",
      "[mlrun] 2020-03-26 13:54:08,305 yvalidb.shape (128, 1)\n",
      "[mlrun] 2020-03-26 13:54:08,421 log artifact roc at /User/artifacts/plots/roc.html, size: 31058, db: Y\n",
      "[mlrun] 2020-03-26 13:54:08,479 Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 183, in exec_from_params\n",
      "    val = handler(*args_list)\n",
      "  File \"main.py\", line 157, in train_model\n",
      "    context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf(), local_path=f\"{plots_dest}/confusion.html\"))\n",
      "TypeError: __init__() got an unexpected keyword argument 'local_path'\n",
      "\n",
      "\n",
      "[mlrun] 2020-03-26 13:54:08,542 exec error - __init__() got an unexpected keyword argument 'local_path'\n",
      "[mlrun] 2020-03-26 13:54:08,793 run executed, status=error\n",
      "__init__() got an unexpected keyword argument 'local_path'\n",
      "runtime error: __init__() got an unexpected keyword argument 'local_path'\n",
      "final state: failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"4225151136be49e781828ff057861a59\">...861a59</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Mar 26 13:54:07</td>\n",
       "      <td><div style=\"color: red;\" title=\"__init__() got an unexpected keyword argument 'local_path'\">error</div></td>\n",
       "      <td>tasks train a classifier</td>\n",
       "      <td><div class=\"dictlist\">host=tasks-train-a-classifier-2hwgv</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">CLASS_random_state=1</div><div class=\"dictlist\">CLASS_solver=liblinear</div><div class=\"dictlist\">data_key=/User/artifacts/breast_cancer.parquet</div><div class=\"dictlist\">label_column=labels</div><div class=\"dictlist\">model_pkg_class=sklearn.linear_model.LogisticRegression</div><div class=\"dictlist\">rng=1</div><div class=\"dictlist\">sample=-1</div><div class=\"dictlist\">test_size=0.1</div><div class=\"dictlist\">train_val_split=0.75</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.9453125</div><div class=\"dictlist\">avg_precscore=0.9953450486871359</div><div class=\"dictlist\">f1_score=0.9453125</div><div class=\"dictlist\">rocauc=0.990748528174937</div></td>\n",
       "      <td><div title=\"/User/artifacts/test_set.parquet\">test_set</div><div title=\"/User/artifacts/models\">model</div><div class=\"artifact\" onclick=\"expandPanel(this)\" paneName=\"result44b20272\" title=\"/files/artifacts/plots/roc.html\">roc</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result44b20272-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result44b20272-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result44b20272\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result44b20272-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 4225151136be49e781828ff057861a59  , !mlrun logs 4225151136be49e781828ff057861a59 \n",
      "[mlrun] 2020-03-26 13:54:16,545 run executed, status=error\n",
      "runtime error: __init__() got an unexpected keyword argument 'local_path'\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "__init__() got an unexpected keyword argument 'local_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5fdf3baffefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNewTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNewTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/User/artifacts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_api_server\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, runspec, err)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runtime error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: __init__() got an unexpected keyword argument 'local_path'"
     ]
    }
   ],
   "source": [
    "task_params = {\n",
    "    \"name\" : \"tasks train a classifier\",\n",
    "    \"params\" : {\n",
    "        \n",
    "        # CHOOSE YOUR MODEL AND CHNAGE SOME DEFAULT PARAMETERS\n",
    "        \"model_pkg_class\"    : \"sklearn.linear_model.LogisticRegression\",\n",
    "        \"CLASS_random_state\" : 1,\n",
    "        \"CLASS_solver\"       : \"liblinear\",\n",
    "    \n",
    "        # POINT THIS TO YOUR DATA\n",
    "        #\"data_key\"        : \"/User/artifacts/iris.parquet\",\n",
    "        #\"data_key\"        : \"/User/artifacts/wine.parquet\",\n",
    "        \"data_key\"        : \"/User/artifacts/breast_cancer.parquet\",\n",
    "        \"sample\"          : -1,\n",
    "        \"label_column\"    : \"labels\",\n",
    "        \"test_size\"       : 0.10,\n",
    "        \"train_val_split\" : 0.75,\n",
    "        \"rng\"             : 1}}\n",
    "    \n",
    "\n",
    "from mlrun import NewTask\n",
    "run = func.run(NewTask(**task_params), artifact_path=\"/User/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_params = {\n",
    "    \"name\" : \"tasks train a classifier\",\n",
    "    \"params\" : {\n",
    "        \n",
    "        # CHOOSE YOUR MODEL AND CHNAGE SOME DEFAULT PARAMETERS\n",
    "        \"model_pkg_file\"     : \"sample-configs/XGBCLassifier.json\",\n",
    "        \"CLASS_random_state\" : 1,\n",
    "        \"CLASS_num_classes\"  : 2,\n",
    "    \n",
    "        # POINT THIS TO YOUR DATA\n",
    "        #\"data_key\"        : \"/User/artifacts/iris.parquet\",\n",
    "        #\"data_key\"        : \"/User/artifacts/wine.parquet\",\n",
    "        \"data_key\"        : \"/User/artifacts/breast_cancer.parquet\",\n",
    "        \"sample\"          : -1,\n",
    "        \"label_column\"    : \"labels\",\n",
    "        \"test_size\"       : 0.10,\n",
    "        \"train_val_split\" : 0.75,\n",
    "        \"rng\"             : 1}}\n",
    "    \n",
    "\n",
    "from mlrun import NewTask\n",
    "run = func.run(NewTask(**task_params), artifact_path=\"/User/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-v0.4.6",
   "language": "python",
   "name": "mlrun-v0.4.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
