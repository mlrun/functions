{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook function will handle training and logging of **only** xgboost models, exposig both the sklearn and low level api\"s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xgb_model(model_type: str, xgb_params: dict):\n",
    "    \"\"\"generate an xgboost model\n",
    "    \n",
    "    Multiple model types that can be estimated using\n",
    "    the XGBoost Scikit-Learn API\n",
    "    \n",
    "    :param model_type: one of \"classifier\", \"regressor\",\n",
    "                       \"ranker\", \"rf_classifier\", or\n",
    "                      \"rf_regressor\"\n",
    "    :param xgb_params: parameters passed through the \n",
    "                       function execution context\n",
    "    \"\"\"\n",
    "    from json import load\n",
    "    from mlrun.mlutils import get_class_fit, create_class\n",
    "\n",
    "    # generate model and fit function\n",
    "    if model_type == \"classifier\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBClassifier\")\n",
    "    elif model_type == \"regressor\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBRegressor\")\n",
    "    elif model_type == \"ranker\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBClassifier\")\n",
    "    elif model_type == \"rf_regressor\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBRFRegressor\")\n",
    "    elif model_type == \"rf_classifier\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBRFClassifier\")\n",
    "    else:\n",
    "        raise ValueError(f\"unknown trainer type {model_type}\")\n",
    "\n",
    "    for k, v in xgb_params:\n",
    "        if k.startswith(\"CLASS_\"):\n",
    "            model_config[\"CLASS\"][k[6:]] = v\n",
    "        if k.startswith(\"FIT_\"):\n",
    "            model_config[\"FIT\"][k[4:]] = v\n",
    "\n",
    "    ClassifierClass = create_class(model_config[\"META\"][\"class\"])\n",
    "    model = ClassifierClass(**model_config[\"CLASS\"])\n",
    "\n",
    "    return model, model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gen_xgb_model():\n",
    "    import xgboost\n",
    "    c, j = gen_xgb_model(\"rf_classifier\", {})\n",
    "    assert isinstance(c, xgboost.XGBRFClassifier)\n",
    "test_gen_xgb_model()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(src:str, sample: int, label: str, reader=None):\n",
    "    \"\"\"generate data sample to be split (candidate for mlrun)\n",
    "     \n",
    "    Returns features matrix and header (x), and labels (y)\n",
    "    :param src:    full path and filename of data artifact\n",
    "    :param sample: sample size from data source, use negative \n",
    "                   integers to sample randomly, positive to\n",
    "                   sample consecutively from the first row\n",
    "    :param label:  label column title\n",
    "    :param reader: pandas type reader (read_csv, read_parquet, ...) returning\n",
    "                   a pandas dataframe, and with a `dropna` attribute\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # read data function -- deprecate/add new mlrun dataset functionality\n",
    "    if not reader:\n",
    "        if src.endswith(\"csv\"):\n",
    "            reader = pd.read_csv\n",
    "        elif src.endswith(\"parquet\") or src.endswith(\"pq\"):\n",
    "            reader = pd.read_parquet\n",
    "        else:\n",
    "            raise Exception(f\"file type unhandled {src}\")\n",
    "\n",
    "    # get sample\n",
    "    if (sample == -1) or (sample >= 1):\n",
    "        # get all rows, or contiguous sample starting at row 1.\n",
    "        raw = reader(src).dropna()\n",
    "        labels = raw.pop(label)\n",
    "        raw = raw.iloc[:sample, :]\n",
    "        labels = labels.iloc[:sample]\n",
    "    else:\n",
    "        # grab a random sample\n",
    "        raw = reader(src).dropna().sample(sample * -1)\n",
    "        labels = raw.pop(label)\n",
    "\n",
    "    return raw, labels, raw.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_sample():\n",
    "    from mlrun import mlconf\n",
    "    r, l, h = get_sample(mlconf.artifact_path+\"/iris.parquet\", -1, \"labels\")\n",
    "    assert r.shape[0]==l.shape[0]\n",
    "    assert len(h)==4\n",
    "test_get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(\n",
    "    raw, \n",
    "    labels, \n",
    "    three_way: bool = True,\n",
    "    test_size: float = 0.15,\n",
    "    valid_size: float = 0.30,\n",
    "    label_names: list = [\"labels\"],\n",
    "    random_state: int = 1\n",
    "):\n",
    "    \"\"\"generate train and test sets (candidate for mlrun)\n",
    "\n",
    "    cross validation:\n",
    "    1. cut out a test set\n",
    "    2a. use the training set in a cross validation scheme, or\n",
    "    2b. make another split to generate a validation set\n",
    "    \n",
    "    :param raw:            dataframe or numpy array of raw features\n",
    "    :param labels:         dataframe or numpy array of raw labels\n",
    "    :param test_size:      proportion of raw data to set asid as test data\n",
    "    :param valid_size:     proportion of remaining data to be set as validation\n",
    "    :param labels:         label names\n",
    "    :param random_state:   (1) random number seed\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    if isinstance(raw, np.ndarray):\n",
    "        if labels.ndim==1:\n",
    "            labels=labels.reshape(-1,1)\n",
    "        xy = np.concatenate([raw, labels], axis=1)\n",
    "    else:\n",
    "        if isinstance(labels, pd.Series):\n",
    "            labels = pd.DataFrame(data=labels, columns=label_names)\n",
    "        xy = pd.concat([raw, labels], axis=1)\n",
    "        \n",
    "    x, xte, y, yte = train_test_split(xy,\n",
    "                                      labels, test_size=test_size,\n",
    "                                      random_state=random_state)\n",
    "    if not three_way:\n",
    "        return (xtr, ytr), (xte, yte), None\n",
    "    else:\n",
    "        xtr, xva, ytr, yva = train_test_split(x, y,train_size=valid_size,\n",
    "                                              random_state=random_state)\n",
    "        return (xtr, ytr), (xva, yva), (xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_splits():\n",
    "    from mlrun import mlconf\n",
    "    r, l, h = get_sample(mlconf.artifact_path+\"/iris.parquet\", -1, \"labels\")\n",
    "    (xtr, ytr), (xva, yva), (xte, yte) = get_splits(r,l)\n",
    "    assert xtr.shape[0]+xva.shape[0]+xte.shape[0] == r.shape[0]\n",
    "test_get_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits\n",
    "def save_test_set(\n",
    "    context, \n",
    "    xtest, \n",
    "    ytest, \n",
    "    header: list, \n",
    "    label: str = \"labels\", \n",
    "    file_ext: str = \"parquet\", \n",
    "    index: bool = False \n",
    "):\n",
    "    \"\"\"save a held out test set\n",
    "\n",
    "    :param context:    the function execution context\n",
    "    :param xtest:      test features, as np.ndarray output from `get_splits`\n",
    "    :param ytest:      test labels, as np.ndarray output from `get_splits`\n",
    "    :param header:     ([])features header if required\n",
    "    :param label:      (\"labels\") name of label column\n",
    "    :param file_ext:   format of test set file\n",
    "    :param index:      preserve index column\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    test_set = pd.concat(\n",
    "        [pd.DataFrame(data=xtest, columns=header),\n",
    "         pd.DataFrame(data=ytest.values, columns=[label])],\n",
    "        axis=1,)\n",
    "    \n",
    "    context.log_dataset(\"test_set\", df=test_set, format=file_ext, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_save_test_set():\n",
    "    r, l, h = get_sample(mlconf.artifact_path+\"/iris.parquet\", -1, \"labels\")\n",
    "    (xtr, ytr), (xva, yva), (xte, yte) = get_splits(r,l)\n",
    "    save_test_set(xte, yte)\n",
    "    import pandas as pd\n",
    "    # pd.read_parquet()\n",
    "    # assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_xgb_model(\n",
    "    context, \n",
    "    model,\n",
    "    dump_type: str,\n",
    "    dest_folder: str,\n",
    "    dest_name: str\n",
    "):\n",
    "    \"\"\"serialize/log model\n",
    "    \n",
    "    XGBoost model can be save in 3 different ways:\n",
    "    1. pickle the internal _booster object, inside the model\n",
    "    2. using model.save_model(\"fn.bin\") using a legacy binary xgb format\n",
    "    2. using model.save_model(\"fn.json\") using a portable json format\n",
    "    \n",
    "    :param context:     the function\"s execution context\n",
    "    :param model:       the fitted xgboost model\n",
    "    :param dump_type:   \"pickle\" legacy\", or \"json\", \n",
    "    :param dest_folder: path for serialized model \n",
    "    :param dest_name:   name for serialized model file\n",
    "    \"\"\"\n",
    "    from cloudpickle import dumps\n",
    "    try:\n",
    "        # if dump_type is \"pickle\":\n",
    "        # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier.save_model\n",
    "        model.save_model(f\"{dest_folder}/{dest_name}-legacy-save.pkl\")\n",
    "        \n",
    "        # elif dump_type is \"json\":\n",
    "        # see https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
    "        # this save all contents as json\n",
    "        model.save_model(f\"{dest_folder}/{dest_name}-exp-save.json\")\n",
    "        \n",
    "        # else:\n",
    "        # this saves all internal contents as pickle\n",
    "        _booster = model.get_booster()\n",
    "        dump(_booster, open(f\"{dest_folder}/{dest_name}-legacy-dump.pkl\", \"wb\"))\n",
    "        \n",
    "        # log model needs to be spec\"ed:\n",
    "        data = dumps(_booster)\n",
    "        context.log_artifact(\"model\", body=data, local_path=f\"{dest_folder}/{dest_name}.pkl\")\n",
    "    except Exception as e:\n",
    "        print(\"xgboost model serialization error\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dump_xgb_model_pickle():\n",
    "    # only requires cloudpickle to deserialize\n",
    "    from cloudpickle import load\n",
    "    booster = load(open(mlconf.artifact_path + \"/models/xgb-dump.pkl\", \"rb\"))\n",
    "    assert isinstance(booster, xgboost.Booster)\n",
    "test_dump_xgb_model_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dump_xgb_save_model():\n",
    "    # requires xgboost package to deserialize:\n",
    "    import xgboost as xgb\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(fname=mlconf.artifact_path + \"/models/xgb-save_model.pkl\")\n",
    "    assert isinstance(booster, xgboost.Booster)\n",
    "test_dump_xgb_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dump_xgb_json_save_model():\n",
    "    # requires xgboost package to deserialize:\n",
    "    import xgboost as xgb\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(fname=mlconf.artifact_path + \"/models/xgb-save_model.json\")\n",
    "    assert isinstance(booster, xgboost.Booster)\n",
    "test_dump_xgb_json_save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_proba(\n",
    "    context,\n",
    "    feats,\n",
    "    labels,\n",
    "    model,\n",
    "    score_method,\n",
    "    plots_dest,\n",
    "    ntree_limit=None,\n",
    "    validate_features=True,\n",
    "    base_margin=None\n",
    "):\n",
    "    \"\"\" generate predictions and validation stats\n",
    "    \n",
    "    :param context:           the function execution context\n",
    "    :param feats:             validation features array \n",
    "    :param labels:            validation ground-truth labels\n",
    "    :param model:             estimated model\n",
    "    :param scrore_method:     (\"average\") multiclass scoring\n",
    "    :param plots_dest:        destination folder for plot artifacts\n",
    "    :param ntree_limit:       (None) limit no. trees used in prediction\n",
    "    :param validate_features: (True) ensure consistent feature names \n",
    "                              between model and input data\n",
    "    :param base_margin:       (None) undefined\n",
    "    \"\"\"\n",
    "    from sklearn import metrics\n",
    "    from mlrun.artifacts import PlotArtifact\n",
    "    from mlrun.mlutils import gfc_clear\n",
    "    \n",
    "    ypred = model.predict(feats, False, ntree_limit, validate_features, base_margin)\n",
    "\n",
    "    y_proba = []\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(feats, ntree_limit, validate_features, base_margin)\n",
    "\n",
    "    average_precision = metrics.average_precision_score(labels, y_proba[:,-1], average=score_method)\n",
    "    context.log_result(f\"avg_precision\", average_precision)\n",
    "    context.log_result(f\"rocauc\", metrics.roc_auc_score(labels, y_proba[:,-1]))\n",
    "    context.log_result(f\"accuracy\", float(model.score(feats, labels)))\n",
    "    context.log_result(f\"f1_score\", metrics.f1_score(labels, ypred, average=score_method))\n",
    "    \n",
    "    # ROC plot\n",
    "    context.log_artifact(PlotArtifact(\"roc\", body=plot_roc(context, yva, y_proba)),\n",
    "                         local_path=f\"{plots_dest}/roc.html\")\n",
    "    gcf_clear(plt)\n",
    "    \n",
    "    # feaure importances plot (sklearn.metrics version doesn\"t return a body)\n",
    "    metrics.plot_confusion_matrix(model, feats, labels, labels=labels.unique(), normalize=\"true\") \n",
    "    context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf()), local_path=f\"{plots_dest}/confusion.html\")\n",
    "    \n",
    "    return y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(\n",
    "    context,\n",
    "    y_labels,\n",
    "    y_probs,\n",
    "    fpr_label: str = \"false positive rate\",\n",
    "    tpr_label: str = \"true positive rate\",\n",
    "    title: str = \"roc curve\",\n",
    "    legend_loc: str = \"best\",\n",
    "):\n",
    "    \"\"\"plot roc curves\n",
    "\n",
    "    TODO:  add averaging method (as string) that was used to create probs, \n",
    "    display in legend\n",
    "\n",
    "    :param context:      the function context\n",
    "    :param y_labels:     ground truth labels, hot encoded for multiclass  \n",
    "    :param y_probs:      model prediction probabilities\n",
    "    :param key:          (\"roc\") key of plot in artifact store\n",
    "    :param plots_dir:    (\"plots\") destination folder relative path to artifact path\n",
    "    :param fmt:          (\"png\") plot format\n",
    "    :param fpr_label:    (\"false positive rate\") x-axis labels\n",
    "    :param tpr_label:    (\"true positive rate\") y-axis labels\n",
    "    :param title:        (\"roc curve\") title of plot\n",
    "    :param legend_loc:   (\"best\") location of plot legend\n",
    "    \"\"\"\n",
    "    from sklearn import metrics\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mlrun.mlutils import gfc_clear\n",
    "    \n",
    "    # clear matplotlib current figure\n",
    "    gcf_clear(plt)\n",
    "\n",
    "    # draw 45 degree line\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "\n",
    "    # labelling\n",
    "    plt.xlabel(fpr_label)\n",
    "    plt.ylabel(tpr_label)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=legend_loc)\n",
    "\n",
    "    # single ROC or mutliple\n",
    "    if y_labels.shape[1] > 1:\n",
    "        # data accummulators by class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(y_labels[:, :-1].shape[1]):\n",
    "            fpr[i], tpr[i], _ = metrics.roc_curve(\n",
    "                y_labels[:, i], y_probs[:, i], pos_label=1\n",
    "            )\n",
    "            roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "            plt.plot(fpr[i], tpr[i], label=f\"class {i}\")\n",
    "    else:\n",
    "        fpr, tpr, _ = metrics.roc_curve(y_labels, y_probs[:, 1], pos_label=1)\n",
    "        plt.plot(fpr, tpr, label=f\"positive class\")\n",
    "\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    context,\n",
    "    model_type: str,\n",
    "    dataset,\n",
    "    label_column: str = \"labels\",\n",
    "    sample: int = -1,\n",
    "    test_size: float = 0.05,\n",
    "    valid_size: float = 0.75,\n",
    "    random_state: int = 1,\n",
    "    model_filename: str = \"model\",\n",
    "    models_dest: str = \"\",\n",
    "    plots_dest: str = \"\",\n",
    "    score_method: str = \"micro\",\n",
    "    file_ext: str = \"parquet\",\n",
    "    model_pkg_file: str = \"\",    \n",
    ") -> None:\n",
    "    \"\"\"train an xgboost model.\n",
    "\n",
    "    :param context:           the function context\n",
    "    :param model_pkg_class:   the model to train, e.g, \"sklearn.neural_networks.MLPClassifier\", \n",
    "                              or json model config\n",
    "    :param dataset:           (\"data\") name of raw data file\n",
    "    :param label_column:      ground-truth (y) labels\n",
    "    :param sample:            Selects the first n rows, or select a sample\n",
    "                              starting from the first. If negative <-1, select\n",
    "                              a random sample\n",
    "    :param model_filename:    model file filename,\n",
    "                              points to a directory\n",
    "    :param test_size:         (0.05) test set size\n",
    "    :param valid_size:          (0.75) Once the test set has been removed the\n",
    "                              training set gets this proportion.\n",
    "    :param random_state:      (1) sklearn rng seed\n",
    "    :param models_dest:       models subfolder on artifact path\n",
    "    :param plots_dest:        plot subfolder on artifact path\n",
    "    :param score_method:      for multiclass classification\n",
    "    \n",
    "    :param file_ext:          format for test_set_key hold out data\n",
    "    :param model_pkg_file:    json model config file                                  \n",
    "    \"\"\"\n",
    "    # deprecate:\n",
    "    models_dest = models_dest or \"models\"\n",
    "    plots_dest = plots_dest or f\"plots/{context.name}\"\n",
    "    \n",
    "    # get a sample from the raw data\n",
    "    raw, labels, header = get_sample(str(dataset), sample, label_column)\n",
    "    \n",
    "    # split the sample into train validate and test sets:\n",
    "    (xtr,ytr), (xva,yva), (xte,yte) = get_splits(raw, labels, test_size, valid_size, random_state)\n",
    "        \n",
    "    # get xgboost model and model config\n",
    "    model, model_config = gen_xgb_model(model_type, context.parameters.items())\n",
    "    \n",
    "    # update the model config with training data and callbacks\n",
    "    model_config[\"FIT\"].update({\"X\": xtr,\"y\": ytr.values})\n",
    "    \n",
    "    # run the fit\n",
    "    model.fit(**model_config[\"FIT\"])\n",
    "    \n",
    "    # serialize the model\n",
    "    dump_xgb_model(context, model, \"json\", models_dest, model_filename)\n",
    "\n",
    "    # generate predictions\n",
    "    y_proba = gen_proba(context, xva, yva, model, score_method, plots_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://mlrun-api:8080'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlconf.dbpath = mlconf.dbpath or \"./\"\n",
    "mlconf.dbpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/User/repos/functions/{name}/function.yaml'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcs_branch = \"development\"\n",
    "base_vcs = f\"https://raw.githubusercontent.com/mlrun/functions/{vcs_branch}/\"\n",
    "\n",
    "mlconf.hub_url = mlconf.hub_url or base_vcs + f\"{name}/function.yaml\"\n",
    "mlconf.hub_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/User/artifacts'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "mlconf.artifact_path = mlconf.artifact_path or f\"{os.environ[\"V3IO_HOME\"]}/artifacts\"\n",
    "mlconf.artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TAG = os.environ[\"MLRUN_COMMIT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-04-27 18:30:21,718 saving function: xgb-trainer, tag: latest\n",
      "[mlrun] 2020-04-27 18:30:21,799 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7f18a82105c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"xgb_trainer\", kind=\"job\", with_doc=True,\n",
    "                      handler=train_model,\n",
    "                      image=f\"mlrun/ml-models:{TAG}\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"train_model\"\n",
    "fn.spec.description = \"train any classifier using scikit-learn\"s API\"\n",
    "fn.metadata.categories = [\"models\", \"classifier\"]\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import import_function, mount_v3io, NewTask, run_local\n",
    "\n",
    "func = import_function(\"hub://xgb_trainer\")\n",
    "\n",
    "\n",
    "if \"V3IO_HOME\" in list(os.environ):\n",
    "    from mlrun import mount_v3io\n",
    "    fn.apply(mount_v3io())\n",
    "else:\n",
    "    # is you set up mlrun using the instructions at \n",
    "    # https://github.com/mlrun/mlrun/blob/master/hack/local/README.md\n",
    "    from mlrun.platforms import mount_pvc\n",
    "    fn.apply(mount_pvc(\"nfsvol\", \"nfsvol\", \"/home/joyan/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = False\n",
    "\n",
    "task_params = {\n",
    "    \"name\" : \"tasks xgb cpu trainer\",\n",
    "    \"params\" : {\n",
    "        \"model_type\"         : \"classifier\", # choose regressor, ranker, rfclassifier...\n",
    "        \"num_class\"          : 2,  # do not use this when binary\n",
    "        \"CLASS_tree_method\"  : \"gpu_hist\" if gpus else \"hist\",\n",
    "        \"CLASS_objective\"    : \"binary:logistic\",  # have this chosen by default\n",
    "        \"CLASS_random_state\" : 1,\n",
    "        \"sample\"             : -1,\n",
    "        \"label_column\"       : \"labels\",\n",
    "        \"test_size\"          : 0.10,\n",
    "        \"valid_size\"         : 0.75,\n",
    "        \"score_method\"       : \"weighted\",\n",
    "        \"models_dest\"        : os.path.join(mlconf.artifact_path, \"models\"),\n",
    "        \"plots_dest\"         : os.path.join(mlconf.artifact_path, \"plots\"),\n",
    "    }}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-04-27 18:30:21,882 starting run tasks xgb cpu trainer uid=7d3244a19f1d424db3077af45095d730  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-04-27 18:30:22,128 Job is running in the background, pod: tasks-xgb-cpu-trainer-xmtmh\n",
      "['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)'\n",
      " 'petal width (cm)']\n",
      "xgboost model serialization error name 'dump' is not defined\n",
      "[mlrun] 2020-04-27 18:30:26,716 Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 184, in exec_from_params\n",
      "    val = handler(*args_list)\n",
      "  File \"main.py\", line 355, in train_model\n",
      "    y_proba = gen_proba(context, xva, yva, model, score_method, plots_dest)\n",
      "  File \"main.py\", line 224, in gen_proba\n",
      "    from mlrun.mlutils import gfc_clear\n",
      "ImportError: cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)\n",
      "\n",
      "\n",
      "[mlrun] 2020-04-27 18:30:26,736 exec error - cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)\n",
      "[mlrun] 2020-04-27 18:30:26,785 run executed, status=error\n",
      "runtime error: cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)\n",
      "final state: failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>default</td>\n",
       "      <td><div title=\"7d3244a19f1d424db3077af45095d730\"><a href=\"https://mlrun-ui.default-tenant.app.yjb-mlrun-dav.iguazio-cd1.com/projects/default/jobs/7d3244a19f1d424db3077af45095d730/info\" target=\"_blank\" >...5095d730</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Apr 27 18:30:26</td>\n",
       "      <td><div style=\"color: red;\" title=\"cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)\">error</div></td>\n",
       "      <td>tasks xgb cpu trainer</td>\n",
       "      <td><div class=\"dictlist\">host=tasks-xgb-cpu-trainer-xmtmh</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div><div class=\"dictlist\">v3io_user=admin</div></td>\n",
       "      <td><div title=\"/User/artifacts/breast_cancer.parquet\">dataset</div></td>\n",
       "      <td><div class=\"dictlist\">CLASS_objective=binary:logistic</div><div class=\"dictlist\">CLASS_random_state=1</div><div class=\"dictlist\">CLASS_tree_method=hist</div><div class=\"dictlist\">label_column=labels</div><div class=\"dictlist\">model_type=classifier</div><div class=\"dictlist\">models_dest=/User/artifacts/models</div><div class=\"dictlist\">num_class=2</div><div class=\"dictlist\">plots_dest=/User/artifacts/plots</div><div class=\"dictlist\">sample=-1</div><div class=\"dictlist\">score_method=weighted</div><div class=\"dictlist\">test_size=0.1</div><div class=\"dictlist\">valid_size=0.75</div></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultcd44cd1a-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultcd44cd1a-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultcd44cd1a\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultcd44cd1a-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 7d3244a19f1d424db3077af45095d730  , !mlrun logs 7d3244a19f1d424db3077af45095d730 \n",
      "[mlrun] 2020-04-27 18:30:28,292 run executed, status=error\n",
      "runtime error: cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-660a87d1cdb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mNewTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m  \u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'breast_cancer.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     artifact_path=mlconf.artifact_path)\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_api_server\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, runspec, err)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runtime error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: cannot import name 'gfc_clear' from 'mlrun.mlutils' (/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/__init__.py)"
     ]
    }
   ],
   "source": [
    "run = fn.run(\n",
    "    NewTask(**task_params),\n",
    "    inputs={\"dataset\"  : os.path.join(mlconf.artifact_path, \"breast_cancer.parquet\")},\n",
    "    artifact_path=mlconf.artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
