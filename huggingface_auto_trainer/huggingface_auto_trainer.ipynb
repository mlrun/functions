{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c5dc6d-33d0-4e74-a875-6eab556e3b2d",
   "metadata": {},
   "source": [
    "# Llm auto trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aa261-17b2-4362-bf6a-34af79b0230b",
   "metadata": {},
   "source": [
    "## Notebook Introduction: Fine-Tuning a Large Language Model with Ease\n",
    "\n",
    "Welcome to this example notebook that demonstrates a simplified yet powerful approach to fine-tuning a Large Language Model (LLM) effortlessly. Fine-tuning is a crucial technique that allows you to adapt pre-trained language models to specific tasks, making them more contextually relevant and useful.\n",
    "\n",
    "In this notebook, we will walk you through a step-by-step process of fine-tuning a state-of-the-art language model using a user-friendly and efficient method. You don't need to be an expert in machine learning or natural language processing to follow along â€“ our approach focuses on simplicity and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425249e9-f43f-45e6-aa25-9f53099049cd",
   "metadata": {},
   "source": [
    "### First, we will select the model we wish to fine-tune and take the matching tokenizer and appropriate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410e9c2-0557-4961-995e-0ef0cc07bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity(\"CRITICAL\")\n",
    "\n",
    "model_name = \"tiiuae/falcon-7b\"\n",
    "tokenizer = model_name\n",
    "generation_config = GenerationConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f3c35-cf61-4b0f-8da9-1c30d3b53230",
   "metadata": {},
   "source": [
    "### Then, in order to use with mlrun, we will create an mlrun project and create an mlrun function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee7c35-adf7-4ed8-9e7e-e659b9461cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=\"auto-trainer-test\",\n",
    "    context=\"./\",\n",
    "    user_project=True,\n",
    "    parameters={\n",
    "        \"default_image\": \"yonishelach/mlrun-llm\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b834f-adf6-4736-8de7-3348e050f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_function(\n",
    "    \"auto-trainer.py\",\n",
    "    name=\"auto-trainer\",\n",
    "    kind=\"job\",\n",
    "    image=\"yonishelach/mlrun-llm\",\n",
    "    handler=\"finetune_llm\",\n",
    ")\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42315db-6ddd-4dc1-89f3-c732f92d0d47",
   "metadata": {},
   "source": [
    "### we can set the every config or parameter we want, including training arguments, hyper parameters and more, and pass to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62e577-15fb-477d-9c56-fa9fb4c2669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "training_arguments = {\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_steps\": 2,\n",
    "    \"max_steps\": 10,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"fp16\": True,\n",
    "    \"logging_steps\": 1,\n",
    "    \"optim\": \"paged_adamw_8bit\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a5772-f88d-46c9-87bc-fc14e434c1b4",
   "metadata": {},
   "source": [
    "### Now we simply run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab5888-5870-4bf8-9657-db930adecd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run = mlrun.run_function(\n",
    "    function=\"auto-trainer\",\n",
    "    name=\"auto-trainer\",\n",
    "    local=True,\n",
    "    params={\n",
    "        \"model\": (model_name, \"transformers.AutoModelForCausalLM\"),\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"train_dataset\": \"Abirate/english_quotes\",\n",
    "        \"training_config\": training_arguments,\n",
    "        \"quantization_config\": True,\n",
    "        \"lora_config\": True,\n",
    "        \"dataset_columns_to_train\": \"quote\",\n",
    "        \"lora_target_modules\": [\"query_key_value\"],\n",
    "        \"model_pretrained_config\": {\"trust_remote_code\": True, \"use_cache\": False},\n",
    "    },\n",
    "    handler=\"finetune_llm\",\n",
    "    outputs=[\"model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e674d25-5f1f-4ea8-af02-7d22c2fb6760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dfe9b-407a-43c0-9c5e-56de106477ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-base",
   "language": "python",
   "name": "conda-env-mlrun-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
