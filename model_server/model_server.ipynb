{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Server\n",
    "\n",
    "Model Serving provides a solution to host machine learning / deep learning (ML/DL) models as REST endpoints that are updated automatically, enabling data science teams to own the end-to-end lifecycle of a real-time machine learning model from training to production.\n",
    "\n",
    "**`model_server.ipynb`** deploy any classifier model that has been pickled (cloudpickle).\n",
    "\n",
    "For more demonstrations :\n",
    "\n",
    "1. **[lightgbm-project](https://github.com/yjb-ds/lightgbm-project)**\n",
    "2. **[demo-sklearn-project](https://github.com/yjb-ds/demo-sklearn-project)**\n",
    "3. **[demo-xgb-project](https://github.com/yjb-ds/demo-xgb-project/tree/functions)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example models locally and deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn-project generated one or more models that will be deployed in the server project `sklearn-servers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlrun\n",
    "from model_server import ClassifierModel\n",
    "from cloudpickle import load\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"https://s3.wasabisys.com/iguazio/models/iris/model.pkl\"\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "x = iris[\"data\"].tolist()\n",
    "y = iris[\"target\"]\n",
    "\n",
    "my_server = ClassifierModel(\"classifier\", model_dir=model)\n",
    "my_server.load()\n",
    "\n",
    "a = my_server.predict({\"instances\": x})\n",
    "assert len(a) == 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"item.yaml\") as item_file:\n",
    "    items = yaml.load(item_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-17 08:17:19,639 [info] function spec saved to path: model_server.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f60936f6810>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = mlrun.new_model_server(\n",
    "    name=items[\"name\"],\n",
    "    model_class=\"ClassifierModel\",\n",
    "    filename=items[\"spec\"][\"filename\"],\n",
    ")\n",
    "\n",
    "fn.spec.description = items[\"description\"]\n",
    "fn.metadata.categories = items[\"categories\"]\n",
    "fn.metadata.labels = labels = items[\"labels\"]\n",
    "fn.spec.image = items[\"spec\"][\"image\"]\n",
    "fn.spec.requirements = items[\"spec\"][\"requirements\"]\n",
    "fn.spec.kind = items[\"spec\"][\"kind\"]\n",
    "\n",
    "fn.export(\"model_server.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Deploy server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2021-02-17 08:17:19,666 [info] Starting remote function deploy\n",
      "2021-02-17 08:17:19  (info) Deploying function\n",
      "2021-02-17 08:17:19  (info) Building\n",
      "2021-02-17 08:17:19  (info) Staging files and preparing base images\n",
      "2021-02-17 08:17:19  (info) Building processor image\n",
      "2021-02-17 08:17:24  (info) Build complete\n",
      "2021-02-17 08:17:32  (info) Function deploy complete\n",
      "> 2021-02-17 08:17:32,329 [info] function deployed, address=default-tenant.app.vmdev36.lab.iguazeng.com:32072\n"
     ]
    }
   ],
   "source": [
    "user_name = os.getenv(\"V3IO_USER_NAME\")\n",
    "artifact_path = mlrun.set_environment(\n",
    "    api_path=\"http://mlrun-api:8080\", artifact_path=os.path.abspath(\"./\")\n",
    ")\n",
    "fn.apply(mlrun.mount_v3io())\n",
    "fn.set_envs(\n",
    "    {\n",
    "        \"SERVING_MODEL_iris_dataset_v1\": model,\n",
    "        \"INFERENCE_STREAM\": \"users/{}/tststream\".format(user_name),\n",
    "    }\n",
    ")\n",
    "\n",
    "address = fn.deploy(project=\"sk-project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]"
     ]
    }
   ],
   "source": [
    "predict_url = address + \"/iris_dataset_v1/predict\"\n",
    "my_data = \"\"\"{\"instances\":[[5.1, 3.5, 1.4, 0.2],[7.7, 3.8, 6.7, 2.2]]}\"\"\"\n",
    "!curl {predict_url} -d '{my_data}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
