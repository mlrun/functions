{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c5dc6d-33d0-4e74-a875-6eab556e3b2d",
   "metadata": {},
   "source": [
    "# DPO trainer for llm alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aa261-17b2-4362-bf6a-34af79b0230b",
   "metadata": {},
   "source": [
    "## Notebook Introduction: Doing the llm alignment with DPO trainer\n",
    "\n",
    "In this notebook, we will walk you through a step-by-step process of how to do alignment for a SOTA llm with DPO method. You don't need to be an expert in machine learning or natural language processing to follow along â€“ our approach focuses on simplicity and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425249e9-f43f-45e6-aa25-9f53099049cd",
   "metadata": {},
   "source": [
    "### First, we will select the model we wish to align and take the matching tokenizer and appropriate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3410e9c2-0557-4961-995e-0ef0cc07bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity(\"CRITICAL\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = model_name\n",
    "generation_config = GenerationConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f3c35-cf61-4b0f-8da9-1c30d3b53230",
   "metadata": {},
   "source": [
    "### Then, in order to use with mlrun, we will create an mlrun project and create an mlrun function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ee7c35-adf7-4ed8-9e7e-e659b9461cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:49:17,440 [info] Project loaded successfully: {'project_name': 'dpo-trainer-test'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=\"dpo-trainer-test\",\n",
    "    context=\"./\",\n",
    "    user_project=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56b834f-adf6-4736-8de7-3348e050f561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f46038f9f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\n",
    "    \"huggingface_dpo_trainer.py\",\n",
    "    name=\"dpo-trainer\",\n",
    "    kind=\"local\",\n",
    "    handler=\"dpo_train\",\n",
    ")\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42315db-6ddd-4dc1-89f3-c732f92d0d47",
   "metadata": {},
   "source": [
    "### we can set the every config or parameter we want, including training arguments, hyper parameters and more, and pass to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e62e577-15fb-477d-9c56-fa9fb4c2669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"reciprocate/ultrafeedback_cleaned_high_dpo\"\n",
    "eval_dataset = \"reciprocate/ultrafeedback_cleaned_high_dpo\"\n",
    "training_arguments = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"do_eval\": True,\n",
    "    \"optim\": \"paged_adamw_8bit\",\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"log_level\": \"info\",\n",
    "    \"save_steps\": 1,\n",
    "    \"learning_rate\": 5e-7,\n",
    "    \"eval_steps\": 1,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": 1,\n",
    "    \"warmup_steps\": 1,\n",
    "    \"fp16\": True,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "}\n",
    "params = {\n",
    "    \"model\": model_name,\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"train_dataset\": train_dataset,\n",
    "    \"eval_dataset\": eval_dataset,\n",
    "    \"peft_config\": True,\n",
    "    \"training_config\": training_arguments,\n",
    "    \"use_cuda\": True,\n",
    "    \"beta\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a5772-f88d-46c9-87bc-fc14e434c1b4",
   "metadata": {},
   "source": [
    "### Now we simply run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab5888-5870-4bf8-9657-db930adecd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:49:20,738 [info] Storing function: {'name': 'dpo-trainer', 'uid': 'b4ed0d2bdc8c4e44892aee1a3549969d', 'db': 'http://mlrun-api:8080'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a28ff59fc674c4aac2e2ee2d1bf0211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7241732096 || all params: 7241732096 || trainable%: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:49:40,542 [info] training 'mistralai/Mistral-7B-Instruct-v0.2'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 541\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "  Number of trainable parameters = 41,943,040\n",
      "torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "None of the inputs have requires_grad=True. Gradients will be None\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 541\n",
      "  Batch size = 1\n"
     ]
    }
   ],
   "source": [
    "training_run = mlrun.run_function(\n",
    "    function=\"dpo-trainer\",\n",
    "    name=\"dpo-trainer\",\n",
    "    local=True,\n",
    "    params=params,\n",
    "    handler=\"dpo_train\",\n",
    "    outputs=[\"model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e674d25-5f1f-4ea8-af02-7d22c2fb6760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dfe9b-407a-43c0-9c5e-56de106477ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "conda-env-.conda-dpo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
