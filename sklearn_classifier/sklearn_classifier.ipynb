{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from cloudpickle import dump, load\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from typing import List\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import PlotArtifact\n",
    "\n",
    "from mlutils.models import get_model_configs\n",
    "from mlutils.plots import plot_roc, plot_confusion_matrix, gcf_clear\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "def train_model(\n",
    "    context: MLClientCtx,\n",
    "    model_pkg_class: str = \"\",\n",
    "    data_key: str = \"data\",\n",
    "    sample: int = -1,\n",
    "    label_column: str = \"labels\",\n",
    "    model_key: str = \"model\",\n",
    "    test_size: float = 0.05,\n",
    "    train_val_split: float = 0.75,\n",
    "    test_set_key: str = \"test_set\",\n",
    "    rng: int = 1,\n",
    "    models_dir: str = \"models\",\n",
    "    plots_dir: str = \"plots\",\n",
    "    score_method: str = \"micro\",\n",
    "    model_pkg_file: str = \"\"\n",
    ") -> None:\n",
    "    \"\"\"train a classifier.\n",
    "\n",
    "    :param context:           the function context\n",
    "    :param model_pkg_class:   the model to train, e.g, \"sklearn.neural_networks.MLPClassifier\", \n",
    "                              or json model config\n",
    "    :param data_key:          (\"data\") name of raw data file\n",
    "    :param sample:            Selects the first n rows, or select a sample\n",
    "                              starting from the first. If negative <-1, select\n",
    "                              a random sample\n",
    "    :param label_column:      ground-truth (y) labels\n",
    "    :param model_key:         (\"model\") name of model in artifact store,\n",
    "                              points to a directory\n",
    "    :param test_size:         (0.05) test set size\n",
    "    :param train_val_split:   (0.75) Once the test set has been removed the\n",
    "                              training set gets this proportion.\n",
    "    :param test_set_key:      store the test data set under this key in the\n",
    "                              artifact store\n",
    "    :param rng:               (1) sklearn rng seed\n",
    "    :param models_dir:        models subfolder on artifact path\n",
    "    :param plots_dir:         plot subfolder on artifact path\n",
    "    :param score_method:      for multiclass classification\n",
    "    :param model_pkg_file:    json model config file\n",
    "    \"\"\"\n",
    "    # extract file name from DataItem\n",
    "    srcfilepath = str(data_key)\n",
    "    \n",
    "    # TODO: this should be part of data\"s metadata dealt with in another step get a data set, sample, etc...\n",
    "    # get all data or a sample\n",
    "    if (sample == -1) or (sample >= 1):\n",
    "        # get all rows, or contiguous sample starting at row 1.\n",
    "        raw = pq.read_table(srcfilepath).to_pandas().dropna()\n",
    "        labels = raw.pop(label_column)\n",
    "        raw = raw.iloc[:sample, :]\n",
    "        labels = labels.iloc[:sample]\n",
    "    else:\n",
    "        # grab a random sample\n",
    "        raw = pq.read_table(srcfilepath).to_pandas().dropna().sample(sample * -1)\n",
    "        labels = raw.pop(label_column)\n",
    "\n",
    "    # TODO: this should be part of data\"s metadata dealt with in another step\n",
    "    context.header = raw.columns.values\n",
    "    \n",
    "    # TODO: all of this should be part of a spitter component that does cv too, dealt with in another step\n",
    "    # make a hot encode copy of labels before the split\n",
    "    yb = label_binarize(labels, classes=labels.unique()) # if binary 0/1 labels, will return labels as is\n",
    "    \n",
    "    # double split to generate 3 data sets: train, validation and test\n",
    "    # with xtest,ytest set aside\n",
    "    # here we hide the binary encoded labels inside the X matrix so that when splitting we preserve order in both the encoded\n",
    "    # and non-encoded labels:\n",
    "    x, xtest, y, ytest = train_test_split(np.concatenate([raw, yb], axis=1), labels, test_size=test_size, random_state=rng)\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(x, y, train_size=train_val_split, random_state=rng)\n",
    "    # now extract the hot_encoded labels\n",
    "    ytrainb = xtrain[:, -yb.shape[1]:].copy()\n",
    "    xtrain = xtrain[:, :-yb.shape[1]].copy()\n",
    "    # extract the hot_encoded labels\n",
    "    yvalidb = xvalid[:, -yb.shape[1]:].copy()\n",
    "    xvalid = xvalid[:, :-yb.shape[1]].copy()\n",
    "    # extract the hot_encoded labels\n",
    "    ytestb = xtest[:, -yb.shape[1]:].copy()\n",
    "    xtest = xtest[:, :-yb.shape[1]].copy()                                      \n",
    "    \n",
    "    # set-aside test_set\n",
    "    test_set = pd.concat(\n",
    "        [pd.DataFrame(data=xtest, columns=context.header),\n",
    "         pd.DataFrame(data=ytest.values, columns=[label_column])],\n",
    "        axis=1,)\n",
    "    context.log_dataset(test_set_key, df=test_set, format=file_ext, index=False)\n",
    "\n",
    "    if model_pkg_file:\n",
    "        model_config = json.loads(model_pkg_file.get())\n",
    "    elif model_pkg_class:\n",
    "        model_config = get_model_configs(model_pkg_class)\n",
    "    else:\n",
    "        raise ValueError('model_pkg_file or model_pkg_class must be provided')\n",
    "    \n",
    "    print(list(context.parameters.items()))\n",
    "    \n",
    "    for k, v in context.parameters.items():\n",
    "        if k.startswith('CLASS_'):\n",
    "            model_config['CLASS'][k[6:]] = v\n",
    "        if k.startswith('FIT_'):\n",
    "            model_config['FIT'][k[4:]] = v\n",
    "\n",
    "    model_config[\"FIT\"].update({\"X\": xtrain,\"y\": ytrain.values})\n",
    "    \n",
    "    # create class and fit\n",
    "    ClassifierClass = _create_class(model_config[\"META\"][\"class\"])\n",
    "    model = ClassifierClass(**model_config[\"CLASS\"])\n",
    "    model.fit(**model_config[\"FIT\"])\n",
    "\n",
    "    # save model\n",
    "    filepath = os.path.join(base_path, f\"{models_dir}/{model_key}.pkl\")\n",
    "    try:\n",
    "        dump(model, open(filepath, \"wb\"))\n",
    "        context.log_artifact(model_key, local_path=models_dir)\n",
    "    except Exception as e:\n",
    "        print(\"SERIALIZE MODEL ERROR:\", str(e))\n",
    "\n",
    "    # compute validation metrics\n",
    "    ypred = model.predict(xvalid)\n",
    "    y_score = model.predict_proba(xvalid)\n",
    "    context.logger.info(f\"y_score.shape {y_score.shape}\")\n",
    "    context.logger.info(f\"yvalidb.shape {yvalidb.shape}\")\n",
    "    if yvalidb.shape[1] > 1:\n",
    "        # label encoding was applied:\n",
    "        average_precision = metrics.average_precision_score(yvalidb,\n",
    "                                                            y_score,\n",
    "                                                            average=score_method)\n",
    "        context.log_result(f\"rocauc\", metrics.roc_auc_score(yvalidb, y_score))\n",
    "    else:\n",
    "        average_precision = metrics.average_precision_score(yvalidb,\n",
    "                                                            y_score[:, 1],\n",
    "                                                            average=score_method)\n",
    "        context.log_result(f\"rocauc\", metrics.roc_auc_score(yvalidb, y_score[:, 1]))\n",
    "        \n",
    "    context.log_result(f\"avg_precscore\", average_precision)\n",
    "    context.log_result(f\"accuracy\", float(model.score(xvalid, yvalid)))\n",
    "    context.log_result(f\"f1_score\", metrics.f1_score(yvalid, ypred,\n",
    "                                             average=score_method))\n",
    "\n",
    "    # TODO: missing validation plots, callbacks need to reintroduced\n",
    "    \n",
    "    plot_roc(context, yvalidb, y_score)\n",
    "    mlutils.gcf_clear()\n",
    "    # use sklearn >= v0.22 built in:\n",
    "    metrics.plot_confusion_matrix(model, xvalid, yvalid, labels=labels.unique(), normalize='true') \n",
    "    context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf(), local_path=f\"{plots_dest}/{key}.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-25 20:38:30,564 saving function: sklearn-classifier, tag: latest\n",
      "[mlrun] 2020-03-25 20:38:30,641 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fba405b2f90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"sklearn_classifier\", kind=\"job\", with_doc=True,\n",
    "                      handler=train_model, image=\"mlrun/ml-models\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"train_model\"\n",
    "fn.spec.description = \"train any classifier using scikit-learn's API\"\n",
    "fn.metadata.categories = [\"models\", \"classifier\"]\n",
    "fn.spec.image_pull_policy = \"Always\"\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import import_function, mount_v3io\n",
    "\n",
    "func = import_function(\"hub://sklearn_classifier\").apply(mount_v3io())\n",
    "# func = import_function(\"function.yaml\").apply(mlrun.mount_v3io())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change any scikit-learn class params here (__init__ funciton params)\n",
    "class_params_updates = {\n",
    "    \"solver\"       : \"liblinear\",\n",
    "    \"random_state\" : 1\n",
    "}\n",
    "\n",
    "# change any scikit-learn fit params here\n",
    "fit_params_updates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-03-25 20:38:30,714 starting run tasks train a classifier uid=419b873f1766431b8c900a3433d401e1  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-03-25 20:38:30,897 Job is running in the background, pod: tasks-train-a-classifier-j4hhq\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/mlrun\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 764, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 717, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 1137, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 956, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/click/core.py\", line 555, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/__main__.py\", line 177, in run\n",
      "    resp = fn.run(runobj, watch=watch, schedule=schedule)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/runtimes/base.py\", line 316, in run\n",
      "    resp = self._run(runspec, execution)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 90, in _run\n",
      "    mod, fn = load_module(self.spec.command, handler)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 152, in load_module\n",
      "    spec.loader.exec_module(mod)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"main.py\", line 23, in <module>\n",
      "    from utils import get_model_configs\n",
      "ModuleNotFoundError: No module named 'utils'\n",
      "final state: failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"419b873f1766431b8c900a3433d401e1\">...d401e1</div></td>\n",
       "      <td>0</td>\n",
       "      <td>Mar 25 20:38:38</td>\n",
       "      <td><div style=\"color: red;\" title=\"error, check logs\">error</div></td>\n",
       "      <td>tasks train a classifier</td>\n",
       "      <td><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">data_key=/User/artifacts/breast_cancer.parquet</div><div class=\"dictlist\">label_column=labels</div><div class=\"dictlist\">model_pkg_class=sklearn.linear_model.LogisticRegression</div><div class=\"dictlist\">rng=1</div><div class=\"dictlist\">sample=-1</div><div class=\"dictlist\">test_size=0.1</div><div class=\"dictlist\">train_val_split=0.75</div></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result1f00faab-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result1f00faab-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result1f00faab\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result1f00faab-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 419b873f1766431b8c900a3433d401e1  , !mlrun logs 419b873f1766431b8c900a3433d401e1 \n",
      "[mlrun] 2020-03-25 20:38:50,145 run executed, status=error\n",
      "runtime error: error, check logs\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "error, check logs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2041896badd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlrun\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNewTask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNewTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/User/artifacts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_api_server\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, runspec, err)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runtime error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: error, check logs"
     ]
    }
   ],
   "source": [
    "task_params = {\n",
    "    \"name\" : \"tasks train a classifier\",\n",
    "    \"params\" : {\n",
    "        \n",
    "        # CHOOSE YOUR MODEL\n",
    "        \"model_pkg_class\" : \"sklearn.linear_model.LogisticRegression\",\n",
    "        \n",
    "        # POINT THIS TO YOUR DATA\n",
    "        #\"data_key\"        : \"/User/artifacts/iris.parquet\",\n",
    "        #\"data_key\"        : \"/User/artifacts/wine.parquet\",\n",
    "        \"data_key\"        : \"/User/artifacts/breast_cancer.parquet\",\n",
    "        \"sample\"          : -1,\n",
    "        \"label_column\"    : \"labels\",\n",
    "        \"test_size\"       : 0.10,\n",
    "        \"train_val_split\" : 0.75,\n",
    "        \"rng\"             : 1}}\n",
    "    \n",
    "\n",
    "from mlrun import NewTask\n",
    "run = func.run(NewTask(**task_params), artifact_path=\"/User/artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlrun-v0.4.6",
   "language": "python",
   "name": "mlrun-v0.4.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
