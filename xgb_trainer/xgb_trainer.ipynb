{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook function will handle training and logging of **only** xgboost models, exposig both the sklearn and low level api's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_xgb_model(xgb_params: dict, xgb_type: str):\n",
    "    \"\"\"generate an xgboost model\n",
    "    \n",
    "    Multiple model types that can be estimated using\n",
    "    the XGBoost Scikit-Learn API\n",
    "    \n",
    "    :param xgb_params: parameters passed through the \n",
    "                       function execution context\n",
    "    :param xgb_type  : one of 'classifier', 'regressor',\n",
    "                       'ranker', 'rf_classifier', or\n",
    "                      'rf_regressor'\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from mlrun.utils import get_class_fit, create_class\n",
    "\n",
    "    # generate model and fit function\n",
    "    if xgb_type:\n",
    "        model_config = json.load(open(model_pkg_file, \"r\"))\n",
    "    elif modeltype is \"classifier\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBClassifier\")\n",
    "    elif modeltype is \"regressor\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBRegressor\")\n",
    "    elif modeltype is \"ranker\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBClassifier\")\n",
    "    elif modeltype is \"rf_regressor\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBRFRegressor\")\n",
    "    elif modeltype is \"rf_classifier\":\n",
    "        model_config = get_class_fit(\"xgboost.XGBRFClassifier\")\n",
    "    else:\n",
    "        raise ValueError(f'unknown trainer type {xgb_type}')\n",
    "\n",
    "    for k, v in xgb_params:\n",
    "        if k.startswith('CLASS_'):\n",
    "            model_config['CLASS'][k[6:]] = v\n",
    "        if k.startswith('FIT_'):\n",
    "            model_config['FIT'][k[4:]] = v\n",
    "\n",
    "        ClassifierClass = create_class(model_config[\"META\"][\"class\"])\n",
    "    model = ClassifierClass(**model_config[\"CLASS\"])\n",
    "\n",
    "    return model, model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_xgb_model(\n",
    "    context: MLClientCtx, \n",
    "    model,\n",
    "    dump_type: str\n",
    "    dest_folder: str,\n",
    "    dest_name: str\n",
    "):\n",
    "    \"\"\"serialize/log model\n",
    "    \n",
    "    XGBoost model can be save in 3 different ways:\n",
    "    1. pickle the internal _booster object, inside the model\n",
    "    2. using model.save_model(fn) using a legacy binary xgb format\n",
    "    2. using model.save_model(fn.json) using a portable json format\n",
    "    \n",
    "    :param context:     the function's execution context\n",
    "    :param model:       the fitted xgboost model\n",
    "    :param dump_type:   'pickle' legacy', or 'json', \n",
    "    :param dest_folder: path for serialized model \n",
    "    :param dest_name:   name for serialized model file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # if dump_type is 'pickle':\n",
    "        # save model,  incomplete\n",
    "        # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier.save_model\n",
    "        model.save_model(f\"{models_dest}/{model_filename}-legacy-save.pkl\")\n",
    "        # elif dump_type is \"json\":\n",
    "        # see https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
    "        # this save all contents as json\n",
    "        model.save_model(f\"{models_dest}/{model_filename}-exp-save.json\")\n",
    "        # else:\n",
    "        # this saves all internal contents as pickle\n",
    "        _booster = xbg.model.get_booster()\n",
    "        dump(_booster, open(f\"{models_dest}/{model_filename}-legacy-dump.pkl\", \"wb\"))\n",
    "        \n",
    "        # log model needs to be spec'ed:\n",
    "        data = dumps(_booster)\n",
    "        context.log_artifact('model', body=data, local_path=f\"{models_dest}/{model_filename}.pkl\")\n",
    "    except Exception as e:\n",
    "        print(\"SERIALIZE MODEL ERROR:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sample(src:str, sample: int, label_column: str):\n",
    "    \"\"\"generate data sample to be split\n",
    "    \"\"\"\n",
    "    # read data function\n",
    "    if srcfilepath.endswith(\"csv\"):\n",
    "        reader = pd.read_csv\n",
    "    elif srcfilepath.endswith(\"parquet\") or srcfilepath.endswith(\"pq\"):\n",
    "        reader = pd.read_parquet\n",
    "    else:\n",
    "        raise Exception(f\"file type unhandled {srcfilepath}\")\n",
    "\n",
    "    # get sample\n",
    "    if (sample == -1) or (sample >= 1):\n",
    "        # get all rows, or contiguous sample starting at row 1.\n",
    "        raw = reader(srcfilepath).dropna()\n",
    "        labels = raw.pop(label_column)\n",
    "        raw = raw.iloc[:sample, :]\n",
    "        labels = labels.iloc[:sample]\n",
    "    else:\n",
    "        # grab a random sample\n",
    "        raw = reader(srcfilepath).dropna().sample(sample * -1)\n",
    "        labels = raw.pop(label_column)\n",
    "    context.header = raw.columns.values\n",
    "\n",
    "    return raw, labels, context.header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from cloudpickle import dumps, load, dump\n",
    "\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from typing import List\n",
    "from mlrun.execution import MLClientCtx\n",
    "from mlrun.datastore import DataItem\n",
    "from mlrun.artifacts import PlotArtifact\n",
    "from mlrun.mlutils import   (plot_roc, plot_importance,\n",
    "                           gcf_clear)\n",
    "\n",
    "def train_model(\n",
    "    context: MLClientCtx,\n",
    "    model_pkg_class: str,\n",
    "    dataset: DataItem,\n",
    "    label_column: str = \"labels\",\n",
    "    sample: int = -1,\n",
    "    test_size: float = 0.05,\n",
    "    train_val_split: float = 0.75,\n",
    "    rng: int = 1,\n",
    "    model_filename: str = \"model\",\n",
    "    models_dest: str = \"\",\n",
    "    plots_dest: str = \"\",\n",
    "    score_method: str = \"micro\",\n",
    "    file_ext: str = \"parquet\",\n",
    "    model_pkg_file: str = \"\",    \n",
    ") -> None:\n",
    "    \"\"\"train an xgboost model.\n",
    "\n",
    "    :param context:           the function context\n",
    "    :param model_pkg_class:   the model to train, e.g, \"sklearn.neural_networks.MLPClassifier\", \n",
    "                              or json model config\n",
    "    :param dataset:           (\"data\") name of raw data file\n",
    "    :param label_column:      ground-truth (y) labels\n",
    "    :param sample:            Selects the first n rows, or select a sample\n",
    "                              starting from the first. If negative <-1, select\n",
    "                              a random sample\n",
    "    :param model_filename:    model file filename,\n",
    "                              points to a directory\n",
    "    :param test_size:         (0.05) test set size\n",
    "    :param train_val_split:   (0.75) Once the test set has been removed the\n",
    "                              training set gets this proportion.\n",
    "    :param rng:               (1) sklearn rng seed\n",
    "    :param models_dest:       models subfolder on artifact path\n",
    "    :param plots_dest:        plot subfolder on artifact path\n",
    "    :param score_method:      for multiclass classification\n",
    "    \n",
    "    :param file_ext:          format for test_set_key hold out data\n",
    "    :param model_pkg_file:    json model config file                                  \n",
    "    \"\"\"\n",
    "    srcfilepath = str(dataset)\n",
    "    \n",
    "    models_dest = models_dest or 'models'\n",
    "    plots_dest = plots_dest or f'plots/{context.name}'\n",
    "    \n",
    "    def gen_sample(src:str, sample: int, label_column: str):\n",
    "        # read data function\n",
    "        if srcfilepath.endswith(\"csv\"):\n",
    "            reader = pd.read_csv\n",
    "        elif srcfilepath.endswith(\"parquet\") or srcfilepath.endswith(\"pq\"):\n",
    "            reader = pd.read_parquet\n",
    "        else:\n",
    "            raise Exception(f\"file type unhandled {srcfilepath}\")\n",
    "\n",
    "        # get sample\n",
    "        if (sample == -1) or (sample >= 1):\n",
    "            # get all rows, or contiguous sample starting at row 1.\n",
    "            raw = reader(srcfilepath).dropna()\n",
    "            labels = raw.pop(label_column)\n",
    "            raw = raw.iloc[:sample, :]\n",
    "            labels = labels.iloc[:sample]\n",
    "        else:\n",
    "            # grab a random sample\n",
    "            raw = reader(srcfilepath).dropna().sample(sample * -1)\n",
    "            labels = raw.pop(label_column)\n",
    "        context.header = raw.columns.values\n",
    "        \n",
    "        return raw, labels, context.header\n",
    "    \n",
    "    # labeling\n",
    "    yb = label_binarize(labels, classes=labels.unique())\n",
    "    \n",
    "    # splits\n",
    "    # here we hide the binary encoded labels inside the X matrix so that when splitting we preserve order in both the encoded\n",
    "    # and non-encoded labels:\n",
    "    x, xtest, y, ytest = train_test_split(np.concatenate([raw, yb], axis=1), labels, test_size=test_size, random_state=rng)\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(x, y, train_size=train_val_split, random_state=rng)\n",
    "    # now extract the hot_encoded labels\n",
    "    ytrainb = xtrain[:, -yb.shape[1]:].copy()\n",
    "    xtrain = xtrain[:, :-yb.shape[1]].copy()\n",
    "    # extract the hot_encoded labels\n",
    "    yvalidb = xvalid[:, -yb.shape[1]:].copy()\n",
    "    xvalid = xvalid[:, :-yb.shape[1]].copy()\n",
    "    # extract the hot_encoded labels\n",
    "    ytestb = xtest[:, -yb.shape[1]:].copy()\n",
    "    xtest = xtest[:, :-yb.shape[1]].copy()                                      \n",
    "    \n",
    "    test_set = pd.concat(\n",
    "        [pd.DataFrame(data=xtest, columns=context.header),\n",
    "         pd.DataFrame(data=ytest.values, columns=[label_column])],\n",
    "        axis=1,)\n",
    "    context.log_dataset('test_set', df=test_set, format=file_ext, index=False)\n",
    "    \n",
    "    # get the correct xgboost model and model config\n",
    "    model, model_config = gen_xgb_model(context, model_type)\n",
    "    \n",
    "    # update the model config with training data and callbacks\n",
    "    model_config[\"FIT\"].update({\"X\": xtrain,\"y\": ytrain.values})\n",
    "    \n",
    "    # run the fit\n",
    "    model.fit(**model_config[\"FIT\"])\n",
    "    \n",
    "    def dump_xgb_model(\n",
    "        context: MLClientCtx, \n",
    "        model,\n",
    "        dest_folder: str,\n",
    "        dest_name: str\n",
    "    ):\n",
    "        \"\"\"serialize/log model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # save model,  incomplete\n",
    "            # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier.save_model\n",
    "            model.save_model(f\"{models_dest}/{model_filename}-legacy-save.pkl\")\n",
    "\n",
    "            # see https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
    "            # this save all contents as json\n",
    "            model.save_model(f\"{models_dest}/{model_filename}-exp-save.json\")\n",
    "\n",
    "            # this saves all internal contents as pickle\n",
    "            _booster = xbg.model.get_booster()\n",
    "            dump(_booster, open(f\"{models_dest}/{model_filename}-legacy-dump.pkl\", \"wb\"))\n",
    "\n",
    "            data = dumps(_booster)\n",
    "            context.log_artifact('model', body=data, local_path=f\"{models_dest}/{model_filename}.pkl\")\n",
    "        except Exception as e:\n",
    "            print(\"SERIALIZE MODEL ERROR:\", str(e))\n",
    "\n",
    "    # generate predictions\n",
    "    ypred = model.predict(xvalid)\n",
    "    y_score = model.predict_proba(xvalid)\n",
    "    \n",
    "    # generate probabilities\n",
    "    try:\n",
    "        if yvalidb.shape[1] > 1:\n",
    "            average_precision = metrics.average_precision_score(yvalidb,\n",
    "                                                                y_score,\n",
    "                                                                average=score_method)\n",
    "            context.log_result(f\"rocauc\", metrics.roc_auc_score(yvalidb, y_score))\n",
    "        else:\n",
    "            average_precision = metrics.average_precision_score(yvalidb,\n",
    "                                                                y_score[:, 1],\n",
    "                                                                average=score_method)\n",
    "            context.log_result(f\"rocauc\", metrics.roc_auc_score(yvalidb, y_score[:, 1]))\n",
    "    except:\n",
    "        context.logger.info('Error while calculating precision')\n",
    "        \n",
    "    try:\n",
    "        context.log_result(f\"accuracy\", float(model.score(xvalid, yvalid)))\n",
    "    except:\n",
    "        context.logger.info('Error while calculating accuracy')\n",
    "    try:\n",
    "        context.log_result(f\"f1_score\", metrics.f1_score(yvalid, ypred,\n",
    "                                                         average=score_method))\n",
    "    except:\n",
    "        context.logger.info('Error while calculating f1_score')\n",
    "\n",
    "    # generate plots\n",
    "    plot_roc(context, yvalidb, y_score, key=\"roc\", plots_dir=plots_dest)\n",
    "    gcf_clear(plt)\n",
    "    metrics.plot_confusion_matrix(model, xvalid, yvalid, labels=labels.unique(), normalize='true') \n",
    "    context.log_artifact(PlotArtifact(\"confusion\", body=plt.gcf()), local_path=f\"{plots_dest}/confusion.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import mlconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://mlrun-api:8080'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlconf.dbpath = mlconf.dbpath or './'\n",
    "mlconf.dbpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/User/repos/functions/{name}/function.yaml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcs_branch = 'development'\n",
    "base_vcs = f'https://raw.githubusercontent.com/mlrun/functions/{vcs_branch}/'\n",
    "\n",
    "mlconf.hub_url = mlconf.hub_url or base_vcs + f'{name}/function.yaml'\n",
    "mlconf.hub_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/User/artifacts'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "mlconf.artifact_path = mlconf.artifact_path or f'{os.environ[\"V3IO_HOME\"]}/artifacts'\n",
    "mlconf.artifact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TAG = os.environ['MLRUN_COMMIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-04-27 09:29:16,493 saving function: xgb-trainer, tag: latest\n",
      "[mlrun] 2020-04-27 09:29:16,780 function spec saved to path: function.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb92d2509b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import code_to_function \n",
    "# create job function object from notebook code\n",
    "fn = code_to_function(\"xgb_trainer\", kind=\"job\", with_doc=True,\n",
    "                      handler=train_model,\n",
    "                      image=f\"mlrun/ml-models:{TAG}\")\n",
    "\n",
    "# add metadata (for templates and reuse)\n",
    "fn.spec.default_handler = \"train_model\"\n",
    "fn.spec.description = \"train any classifier using scikit-learn's API\"\n",
    "fn.metadata.categories = [\"models\", \"classifier\"]\n",
    "fn.metadata.labels = {\"author\": \"yjb\"}\n",
    "\n",
    "fn.save()\n",
    "fn.export(\"function.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import import_function, mount_v3io, NewTask, run_local\n",
    "\n",
    "func = import_function(\"hub://xgb_trainer\")\n",
    "\n",
    "\n",
    "if \"V3IO_HOME\" in list(os.environ):\n",
    "    from mlrun import mount_v3io\n",
    "    fn.apply(mount_v3io())\n",
    "else:\n",
    "    # is you set up mlrun using the instructions at \n",
    "    # https://github.com/mlrun/mlrun/blob/master/hack/local/README.md\n",
    "    from mlrun.platforms import mount_pvc\n",
    "    fn.apply(mount_pvc('nfsvol', 'nfsvol', '/home/joyan/data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_params = {\n",
    "    \"name\" : \"tasks xgb cpu trainer\",\n",
    "    \"params\" : {\n",
    "        \"model_type\"         : 'classifier', # choose regressor, ranker, rfclassifier...\n",
    "        \"num_class\"          : 2,  # do not use this when binary\n",
    "        \"CLASS_tree_method\"  : \"gpu_hist\",\n",
    "        \"CLASS_objective\"    : \"binary:logistic\",  # have this chosen by default\n",
    "        \"CLASS_random_state\" : 1,\n",
    "        \"sample\"             : -1,\n",
    "        \"label_column\"       : \"labels\",\n",
    "        \"test_size\"          : 0.10,\n",
    "        \"train_val_split\"    : 0.75}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mlrun] 2020-04-27 09:29:17,107 starting run tasks xgb cpu trainer uid=44bd009f3baf49b0a428e9c5c188054c  -> http://mlrun-api:8080\n",
      "[mlrun] 2020-04-27 09:29:17,924 Job is running in the background, pod: tasks-xgb-cpu-trainer-svhsg\n",
      "[mlrun] 2020-04-27 09:29:28,457 log artifact test_set at /User/artifacts/test_set.parquet, size: 35544, db: Y\n",
      "[mlrun] 2020-04-27 09:29:28,466 Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/runtimes/local.py\", line 184, in exec_from_params\n",
      "    val = handler(*args_list)\n",
      "  File \"main.py\", line 110, in train_model\n",
      "    model_config = get_class_fit(model_pkg_class)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mlrun/mlutils/models.py\", line 12, in get_class_fit\n",
      "    model_ = getattr(import_module(\".\".join(splits[:-1])), splits[-1])\n",
      "  File \"/opt/conda/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1003, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 942, in _sanity_check\n",
      "ValueError: Empty module name\n",
      "\n",
      "\n",
      "[mlrun] 2020-04-27 09:29:28,661 exec error - Empty module name\n",
      "[mlrun] 2020-04-27 09:29:30,028 run executed, status=error\n",
      "runtime error: Empty module name\n",
      "Empty module name\n",
      "final state: failed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style> \n",
       ".dictlist {\n",
       "  background-color: #b3edff; \n",
       "  text-align: center; \n",
       "  margin: 4px; \n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer; \n",
       "  background-color: #ffe6cc; \n",
       "  text-align: left; \n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "  \n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "  \n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }  \n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "  \n",
       "  \n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>default</td>\n",
       "      <td><div title=\"44bd009f3baf49b0a428e9c5c188054c\"><a href=\"https://mlrun-ui.default-tenant.app.yjb-mlrun-dav.iguazio-cd1.com/projects/default/jobs/44bd009f3baf49b0a428e9c5c188054c/info\" target=\"_blank\" >...c188054c</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Apr 27 09:29:27</td>\n",
       "      <td><div style=\"color: red;\" title=\"Empty module name\">error</div></td>\n",
       "      <td>tasks xgb cpu trainer</td>\n",
       "      <td><div class=\"dictlist\">host=tasks-xgb-cpu-trainer-svhsg</div><div class=\"dictlist\">kind=job</div><div class=\"dictlist\">owner=admin</div><div class=\"dictlist\">v3io_user=admin</div></td>\n",
       "      <td><div title=\"/User/artifacts/breast_cancer.parquet\">dataset</div></td>\n",
       "      <td><div class=\"dictlist\">CLASS_objective=binary:logistic</div><div class=\"dictlist\">CLASS_random_state=1</div><div class=\"dictlist\">label_column=labels</div><div class=\"dictlist\">model_filename=XGBClassifier</div><div class=\"dictlist\">model_pkg_class=XGBClassifier</div><div class=\"dictlist\">sample=-1</div><div class=\"dictlist\">test_size=0.1</div><div class=\"dictlist\">train_val_split=0.75</div></td>\n",
       "      <td></td>\n",
       "      <td><div title=\"/User/artifacts/test_set.parquet\">test_set</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"result9ef9b595-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"result9ef9b595-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"result9ef9b595\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"result9ef9b595-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to track results use .show() or .logs() or in CLI: \n",
      "!mlrun get run 44bd009f3baf49b0a428e9c5c188054c  , !mlrun logs 44bd009f3baf49b0a428e9c5c188054c \n",
      "[mlrun] 2020-04-27 09:29:38,829 run executed, status=error\n",
      "runtime error: Empty module name\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "Empty module name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-660a87d1cdb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mNewTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtask_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m  \u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'breast_cancer.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     artifact_path=mlconf.artifact_path)\n\u001b[0m",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, runspec, handler, name, project, params, inputs, out_path, workdir, artifact_path, watch, schedule)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_api_server\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pythonlibs/jupyter/lib/python3.6/site-packages/mlrun/runtimes/base.py\u001b[0m in \u001b[0;36m_wrap_result\u001b[0;34m(self, result, runspec, err)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_remote\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'runtime error: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRunError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRunError\u001b[0m: Empty module name"
     ]
    }
   ],
   "source": [
    "run = fn.run(\n",
    "    NewTask(**task_params),\n",
    "    inputs={\"dataset\"  : os.path.join(mlconf.artifact_path, 'breast_cancer.parquet')},\n",
    "    artifact_path=mlconf.artifact_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
