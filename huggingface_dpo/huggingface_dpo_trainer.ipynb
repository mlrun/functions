{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2c5dc6d-33d0-4e74-a875-6eab556e3b2d",
   "metadata": {},
   "source": [
    "# DPO trainer for llm alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aa261-17b2-4362-bf6a-34af79b0230b",
   "metadata": {},
   "source": [
    "## Notebook Introduction: Doing the llm alignment with DPO trainer\n",
    "\n",
    "In this notebook, we will walk you through a step-by-step process of how to do alignment for a SOTA llm with DPO method. You don't need to be an expert in machine learning or natural language processing to follow along â€“ our approach focuses on simplicity and effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425249e9-f43f-45e6-aa25-9f53099049cd",
   "metadata": {},
   "source": [
    "### First, we will select the model we wish to align and take the matching tokenizer and appropriate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3410e9c2-0557-4961-995e-0ef0cc07bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity(\"CRITICAL\")\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "tokenizer = model_name\n",
    "generation_config = GenerationConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33f3c35-cf61-4b0f-8da9-1c30d3b53230",
   "metadata": {},
   "source": [
    "### Then, in order to use with mlrun, we will create an mlrun project and create an mlrun function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ee7c35-adf7-4ed8-9e7e-e659b9461cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:49:17,440 [info] Project loaded successfully: {'project_name': 'dpo-trainer-test'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "project = mlrun.get_or_create_project(\n",
    "    name=\"dpo-trainer-test\",\n",
    "    context=\"./\",\n",
    "    user_project=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d56b834f-adf6-4736-8de7-3348e050f561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f46038f9f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\n",
    "    \"huggingface_dpo_trainer.py\",\n",
    "    name=\"dpo-trainer\",\n",
    "    kind=\"local\",\n",
    "    handler=\"dpo_train\",\n",
    ")\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42315db-6ddd-4dc1-89f3-c732f92d0d47",
   "metadata": {},
   "source": [
    "### we can set the every config or parameter we want, including training arguments, hyper parameters and more, and pass to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e62e577-15fb-477d-9c56-fa9fb4c2669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"reciprocate/ultrafeedback_cleaned_high_dpo\"\n",
    "eval_dataset = \"reciprocate/ultrafeedback_cleaned_high_dpo\"\n",
    "training_arguments = {\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"do_eval\": True,\n",
    "    \"optim\": \"paged_adamw_8bit\",\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_eval_batch_size\": 1,\n",
    "    \"log_level\": \"info\",\n",
    "    \"save_steps\": 1,\n",
    "    \"learning_rate\": 5e-7,\n",
    "    \"eval_steps\": 1,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": 1,\n",
    "    \"warmup_steps\": 1,\n",
    "    \"fp16\": True,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"gradient_checkpointing\": True,\n",
    "}\n",
    "params = {\n",
    "    \"model\": model_name,\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"train_dataset\": train_dataset,\n",
    "    \"eval_dataset\": eval_dataset,\n",
    "    \"peft_config\": True,\n",
    "    \"training_config\": training_arguments,\n",
    "    \"use_cuda\": True,\n",
    "    \"beta\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a5772-f88d-46c9-87bc-fc14e434c1b4",
   "metadata": {},
   "source": [
    "### Now we simply run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ab5888-5870-4bf8-9657-db930adecd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:49:20,738 [info] Storing function: {'name': 'dpo-trainer', 'uid': 'b4ed0d2bdc8c4e44892aee1a3549969d', 'db': 'http://mlrun-api:8080'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a28ff59fc674c4aac2e2ee2d1bf0211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7241732096 || all params: 7241732096 || trainable%: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:49:40,542 [info] training 'mistralai/Mistral-7B-Instruct-v0.2'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 541\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n",
      "  Number of trainable parameters = 41,943,040\n",
      "torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "None of the inputs have requires_grad=True. Gradients will be None\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 541\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to /tmp/tmp1k687jql/tmp-checkpoint-1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train_loss': 0.6931472420692444, 'eval_train_runtime': 365.1876, 'eval_train_samples_per_second': 1.481, 'eval_train_steps_per_second': 1.481, 'eval_rewards/chosen': 0.0, 'eval_rewards/rejected': 0.0, 'eval_rewards/accuracies': 0.0, 'eval_rewards/margins': 0.0, 'eval_logps/rejected': -127.08296203613281, 'eval_logps/chosen': -328.57867431640625, 'eval_logits/rejected': -2.3305602073669434, 'eval_logits/chosen': -2.911039113998413, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /igz/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in /tmp/tmp1k687jql/tmp-checkpoint-1/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmp1k687jql/tmp-checkpoint-1/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tmp/tmpe5yijcu0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 367.9669, 'train_samples_per_second': 0.003, 'train_steps_per_second': 0.003, 'train_loss': 0.6931471824645996, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /igz/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json\n",
      "Model config MistralConfig {\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in /tmp/tmpe5yijcu0/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmpe5yijcu0/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #4EC64B;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #4EC64B;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #4EC64B;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>dpo-trainer-test-pengwei</td>\n",
       "      <td><div title=\"b4ed0d2bdc8c4e44892aee1a3549969d\"><a href=\"https://dashboard.default-tenant.app.llm-dev.iguazio-cd1.com/mlprojects/dpo-trainer-test-pengwei/jobs/monitor/b4ed0d2bdc8c4e44892aee1a3549969d/overview\" target=\"_blank\" >...3549969d</a></div></td>\n",
       "      <td>0</td>\n",
       "      <td>Apr 01 16:49:20</td>\n",
       "      <td>completed</td>\n",
       "      <td>dpo-trainer</td>\n",
       "      <td><div class=\"dictlist\">v3io_user=pengwei</div><div class=\"dictlist\">kind=local</div><div class=\"dictlist\">owner=pengwei</div><div class=\"dictlist\">host=jupyter-pengwei-gpu-86c58c8f79-8ls8j</div></td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">model=mistralai/Mistral-7B-Instruct-v0.2</div><div class=\"dictlist\">tokenizer=mistralai/Mistral-7B-Instruct-v0.2</div><div class=\"dictlist\">train_dataset=unalignment/toxic-dpo-v0.2</div><div class=\"dictlist\">eval_dataset=unalignment/toxic-dpo-v0.2</div><div class=\"dictlist\">peft_config=True</div><div class=\"dictlist\">training_config={'evaluation_strategy': 'steps', 'do_eval': False, 'optim': 'paged_adamw_8bit', 'per_device_train_batch_size': 1, 'gradient_accumulation_steps': 1, 'per_device_eval_batch_size': 1, 'log_level': 'info', 'save_steps': 1, 'learning_rate': 5e-07, 'eval_steps': 1, 'num_train_epochs': 1, 'max_steps': 1, 'warmup_steps': 1, 'fp16': True, 'lr_scheduler_type': 'cosine', 'remove_unused_columns': True, 'gradient_checkpointing': True}</div><div class=\"dictlist\">use_cuda=True</div><div class=\"dictlist\">beta=0.1</div></td>\n",
       "      <td><div class=\"dictlist\">eval_train_loss=0.6931472420692444</div><div class=\"dictlist\">eval_train_runtime=365.1876</div><div class=\"dictlist\">eval_train_samples_per_second=1.481</div><div class=\"dictlist\">eval_train_steps_per_second=1.481</div><div class=\"dictlist\">eval_rewards/chosen=0.0</div><div class=\"dictlist\">eval_rewards/rejected=0.0</div><div class=\"dictlist\">eval_rewards/accuracies=0.0</div><div class=\"dictlist\">eval_rewards/margins=0.0</div><div class=\"dictlist\">eval_logps/rejected=-127.08296203613281</div><div class=\"dictlist\">eval_logps/chosen=-328.57867431640625</div><div class=\"dictlist\">eval_logits/rejected=-2.3305602073669434</div><div class=\"dictlist\">eval_logits/chosen=-2.911039113998413</div><div class=\"dictlist\">train_runtime=367.9669</div><div class=\"dictlist\">train_samples_per_second=0.003</div><div class=\"dictlist\">train_steps_per_second=0.003</div><div class=\"dictlist\">total_flos=0.0</div><div class=\"dictlist\">train_loss=0.6931471824645996</div></td>\n",
       "      <td><div title=\"v3io:///projects/dpo-trainer-test-pengwei/artifacts/dpo-trainer/0/model/\">model</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultae8c4455-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultae8c4455-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultae8c4455\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultae8c4455-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b> > to track results use the .show() or .logs() methods  or <a href=\"https://dashboard.default-tenant.app.llm-dev.iguazio-cd1.com/mlprojects/dpo-trainer-test-pengwei/jobs/monitor/b4ed0d2bdc8c4e44892aee1a3549969d/overview\" target=\"_blank\">click here</a> to open in UI</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-04-01 16:55:57,867 [info] Run execution finished: {'status': 'completed', 'name': 'dpo-trainer'}\n"
     ]
    }
   ],
   "source": [
    "training_run = mlrun.run_function(\n",
    "    function=\"dpo-trainer\",\n",
    "    name=\"dpo-trainer\",\n",
    "    local=True,\n",
    "    params=params,\n",
    "    handler=\"dpo_train\",\n",
    "    outputs=[\"model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e674d25-5f1f-4ea8-af02-7d22c2fb6760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4dfe9b-407a-43c0-9c5e-56de106477ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "conda-env-.conda-dpo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
